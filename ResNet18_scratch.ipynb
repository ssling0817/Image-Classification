{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.utils.data as data\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.8.1+cu102\n"
     ]
    }
   ],
   "source": [
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define activation function beforehand, due to convenience to use later\n",
    "\n",
    "def activation_func(activation):\n",
    "    return  nn.ModuleDict([\n",
    "        ['relu', nn.ReLU(inplace=True)],\n",
    "        ['leaky_relu', nn.LeakyReLU(negative_slope=0.01, inplace=True)],\n",
    "        ['selu', nn.SELU(inplace=True)],\n",
    "        ['none', nn.Identity()]\n",
    "    ])[activation]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pytorch does not have the ‘auto’ padding in Conv2d\n",
    "from functools import partial\n",
    "class Conv2dAuto(nn.Conv2d):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.padding =  (self.kernel_size[0] // 2, self.kernel_size[1] // 2)\n",
    "        \n",
    "conv3x3 = partial(Conv2dAuto, kernel_size=3, bias=False)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Fundamental residual bolck"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If their sizes mismatch, then the input goes into an identity\n",
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, activation='relu'):\n",
    "        super().__init__()\n",
    "        self.in_channels, self.out_channels, self.activation = in_channels, out_channels, activation\n",
    "        self.blocks = nn.Identity()\n",
    "        self.activate = activation_func(activation)\n",
    "        self.shortcut = nn.Identity()   \n",
    "    \n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        if self.should_apply_shortcut: residual = self.shortcut(x)\n",
    "        x = self.blocks(x)\n",
    "        x += residual\n",
    "        x = self.activate(x)\n",
    "        return x\n",
    "    \n",
    "    @property\n",
    "    def should_apply_shortcut(self):\n",
    "        return self.in_channels != self.out_channels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Allow to increase out_channels and define shorcut"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ResNetResidualBlock : 1x1/ 3x3/ 1x1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNetResidualBlock(ResidualBlock):\n",
    "    def __init__(self, in_channels, out_channels, expansion=1, downsampling=1, conv=conv3x3, *args, **kwargs):#=conv3x3\n",
    "        super().__init__(in_channels, out_channels, *args, **kwargs)\n",
    "        self.expansion, self.downsampling, self.conv = expansion, downsampling, conv\n",
    "        self.shortcut = nn.Sequential(\n",
    "            nn.Conv2d(self.in_channels, self.expanded_channels, kernel_size=1,\n",
    "                      stride=self.downsampling, bias=False),\n",
    "            nn.BatchNorm2d(self.expanded_channels)) if self.should_apply_shortcut else None\n",
    "        \n",
    "        \n",
    "    @property\n",
    "    def expanded_channels(self):\n",
    "        return self.out_channels * self.expansion\n",
    "    \n",
    "    @property\n",
    "    def should_apply_shortcut(self):\n",
    "        return self.in_channels != self.expanded_channels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Combine Convolution and BN Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_bn(in_channels, out_channels, conv, *args, **kwargs):\n",
    "    return nn.Sequential(conv(in_channels, out_channels, *args, **kwargs), nn.BatchNorm2d(out_channels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ResNetBasicBlock: 由兩層 3x3conv/batchnorm/activation 組成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNetBasicBlock(ResNetResidualBlock):\n",
    "    \n",
    "    expansion = 1\n",
    "    def __init__(self, in_channels, out_channels, *args, **kwargs):\n",
    "        super().__init__(in_channels, out_channels, *args, **kwargs)\n",
    "        self.blocks = nn.Sequential(\n",
    "            conv_bn(self.in_channels, self.out_channels, conv=self.conv, bias=False, stride=self.downsampling),\n",
    "            activation_func(self.activation),\n",
    "            conv_bn(self.out_channels, self.expanded_channels, conv=self.conv, bias=False),\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class ResNetBottleNeckBlock(ResNetResidualBlock):\n",
    "    expansion = 4\n",
    "    def __init__(self, in_channels, out_channels, *args, **kwargs):\n",
    "        super().__init__(in_channels, out_channels, expansion=4, *args, **kwargs)\n",
    "        self.blocks = nn.Sequential(\n",
    "           conv_bn(self.in_channels, self.out_channels, self.conv, kernel_size=1),\n",
    "             activation_func(self.activation),\n",
    "             conv_bn(self.out_channels, self.out_channels, self.conv, kernel_size=3, stride=self.downsampling),\n",
    "             activation_func(self.activation),\n",
    "             conv_bn(self.out_channels, self.expanded_channels, self.conv, kernel_size=1),\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ResNetLayer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNetLayer(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, block=ResNetBasicBlock, n=1, *args, **kwargs):#代表有n 個 blocks\n",
    "        super().__init__()\n",
    "        # 'We perform downsampling directly by convolutional layers that have a stride of 2.'\n",
    "        downsampling = 2 if in_channels != out_channels else 1\n",
    "        self.blocks = nn.Sequential(\n",
    "            block(in_channels , out_channels, *args, **kwargs, downsampling=downsampling),\n",
    "            *[block(out_channels * block.expansion, \n",
    "                    out_channels, downsampling=1, *args, **kwargs) for _ in range(n - 1)]\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.blocks(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ResNet Encoder "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNetEncoder(nn.Module):\n",
    "    def __init__(self, in_channels=3, blocks_sizes=[64, 128, 256, 512], deepths=[2,2,2,2], \n",
    "                 activation='relu', block=ResNetBasicBlock, *args, **kwargs):\n",
    "        super().__init__()\n",
    "        self.blocks_sizes = blocks_sizes\n",
    "        \n",
    "        self.gate = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, self.blocks_sizes[0], kernel_size=7, stride=2, padding=3, bias=False),\n",
    "            nn.BatchNorm2d(self.blocks_sizes[0]),\n",
    "            activation_func(activation),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        )\n",
    "        \n",
    "        self.in_out_block_sizes = list(zip(blocks_sizes, blocks_sizes[1:]))\n",
    "        self.blocks = nn.ModuleList([ \n",
    "            ResNetLayer(blocks_sizes[0], blocks_sizes[0], n=deepths[0], activation=activation, \n",
    "                        block=block,*args, **kwargs),\n",
    "            *[ResNetLayer(in_channels * block.expansion, \n",
    "                          out_channels, n=n, activation=activation, \n",
    "                          block=block, *args, **kwargs) \n",
    "              for (in_channels, out_channels), n in zip(self.in_out_block_sizes, deepths[1:])]       \n",
    "        ])\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.gate(x)\n",
    "        for block in self.blocks:\n",
    "            x = block(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ResnetDecoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResnetDecoder(nn.Module):\n",
    "    def __init__(self, in_features, n_classes):\n",
    "        super().__init__()\n",
    "        self.avg = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.decoder = nn.Linear(in_features, n_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.avg(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.decoder(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ResNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet(nn.Module):\n",
    "    \n",
    "    def __init__(self, in_channels, n_classes, *args, **kwargs):\n",
    "        super().__init__()\n",
    "        self.encoder = ResNetEncoder(in_channels, *args, **kwargs)\n",
    "        self.decoder = ResnetDecoder(self.encoder.blocks[-1].blocks[-1].expanded_channels, n_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resnet18(in_channels, n_classes, block=ResNetBasicBlock, *args, **kwargs):\n",
    "    return ResNet(in_channels, n_classes, block=block, deepths=[2, 2, 2, 2], *args, **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "class TVDataset(Dataset):\n",
    "    def __init__(self, dataset, transform=None):\n",
    "        self.dataset = dataset\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "        #sample = {'image': dataset[idx][0], 'label': dataset[idx][1]}\n",
    " \n",
    "        if self.transform:\n",
    "            image = self.transform(dataset[idx][0])\n",
    "        #labels=torch.tensor(labels, dtype=torch.long) \n",
    "        return (image,dataset[idx][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "train_labels=[]\n",
    "#TRAIN_DATA_PATH = 'traindata/'\n",
    "#TEST_BATA_PATH='testdata/'\n",
    "\n",
    "#Airplanes\n",
    "train_images = glob.glob ('traindata/airplane/*')\n",
    "airplane_num=len(train_images)\n",
    "for i in range(airplane_num):\n",
    "    train_labels.extend([0])\n",
    "    \n",
    "#Bird\n",
    "train_images += glob.glob ('traindata/bird/*')\n",
    "bird_num=len(train_images)-airplane_num\n",
    "for i in range(bird_num):\n",
    "    train_labels.extend([1])\n",
    "    \n",
    "#Car\n",
    "train_images += glob.glob ('traindata/car/*')\n",
    "car_num=len(train_images) - airplane_num - bird_num\n",
    "for i in range(car_num):\n",
    "    train_labels.extend([2])\n",
    "\n",
    "#Cat\n",
    "train_images += glob.glob ('traindata/cat/*')\n",
    "cat_num=len(train_images) - airplane_num - bird_num - car_num\n",
    "for i in range(cat_num):\n",
    "    train_labels.extend([3])\n",
    "\n",
    "#Dog\n",
    "train_images += glob.glob ('traindata/dog/*')\n",
    "dog_num=len(train_images) - airplane_num - bird_num - car_num - cat_num\n",
    "for i in range(dog_num):\n",
    "    train_labels.extend([4])\n",
    "    \n",
    "#Horse\n",
    "#train_images += glob.glob ('traindata/horse/*.png')\n",
    "#train_images += glob.glob ('traindata/horse/*.jpg')\n",
    "#train_images += glob.glob ('traindata/horse/*.jpeg')\n",
    "train_images += glob.glob ('traindata/horse/*')\n",
    "horse_num=len(train_images) - airplane_num - bird_num - car_num - cat_num - dog_num\n",
    "for i in range(horse_num):\n",
    "    train_labels.extend([5])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13065"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "c = list(zip(train_images, train_labels))\n",
    "\n",
    "random.shuffle(c)\n",
    "\n",
    "train_images, train_labels = zip(*c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "from PIL import Image\n",
    "class New_TVDataset(Dataset):\n",
    "    def __init__(self, imagelist,labellist, transform=None):\n",
    "        self.image_list = imagelist\n",
    "        self.label_list = labellist\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "        #sample = {'image': dataset[idx][0], 'label': dataset[idx][1]}\n",
    "        image = Image.open(self.image_list[idx]).convert('RGB')\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        #labels=torch.tensor(labels, dtype=torch.long) \n",
    "        return (image, self.label_list[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([transforms.Resize((96,96)),\n",
    "                                transforms.RandomHorizontalFlip(p=0.9),transforms.RandomVerticalFlip(p=0.9),\n",
    "                                transforms.ColorJitter(brightness=(0, 5), contrast=(0, 5), saturation=(0, 5), hue=(-0.1, 0.1)),\n",
    "                                transforms.RandomRotation(30, expand=False, center=(48, 48)),\n",
    "                                transforms.ToTensor(),\n",
    "                                transforms.Normalize(mean = (0.5, 0.5, 0.5), std = (0.5, 0.5, 0.5))\n",
    "                                ])\n",
    "\n",
    "transform1 = transforms.Compose([transforms.Resize((96,96)),\n",
    "                                transforms.ToTensor(),\n",
    "                                transforms.Normalize(mean = (0.5, 0.5, 0.5), std = (0.5, 0.5, 0.5))\n",
    "                                ])\n",
    "#transforms.Grayscale()\n",
    "\n",
    "ratio =0.8\n",
    "TOTAL_SIZE= len(train_images)\n",
    "train_len = round(TOTAL_SIZE * ratio)\n",
    "valid_len = round(TOTAL_SIZE * (1-ratio))\n",
    "val_images=train_images[train_len:]\n",
    "val_labels=train_labels[train_len:]\n",
    "tr_images=train_images[:train_len]\n",
    "tr_labels=train_labels[:train_len]\n",
    "train_dataset=New_TVDataset(tr_images,tr_labels,transform)\n",
    "val_dataset=New_TVDataset(val_images,val_labels,transform1)\n",
    "train_data_loader = torch.utils.data.DataLoader(train_dataset, batch_size=32, shuffle=True) \n",
    "val_data_loader = torch.utils.data.DataLoader(val_dataset, batch_size=32, shuffle=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "transform = transforms.Compose([transforms.Resize((96,96)),\n",
    "                                transforms.RandomHorizontalFlip(p=0.9),transforms.RandomVerticalFlip(p=0.9),\n",
    "                                transforms.ColorJitter(brightness=(0, 5), contrast=(0, 5), saturation=(0, 5), hue=(-0.1, 0.1)),\n",
    "                                transforms.RandomRotation(30, expand=False, center=(48, 48)),\n",
    "                                transforms.ToTensor(),\n",
    "                                transforms.Normalize(mean = (0.5, 0.5, 0.5), std = (0.5, 0.5, 0.5)),\n",
    "                                transforms.Grayscale()])\n",
    "transform1 = transforms.Compose([transforms.Resize((96,96)),\n",
    "                                transforms.ToTensor(),\n",
    "                                transforms.Normalize(mean = (0.5, 0.5, 0.5), std = (0.5, 0.5, 0.5)),\n",
    "                                transforms.Grayscale()])\n",
    "\n",
    "\n",
    "ratio =0.8\n",
    "TOTAL_SIZE= len(dataset)\n",
    "train_len = round(TOTAL_SIZE * ratio)\n",
    "valid_len = round(TOTAL_SIZE * (1-ratio))\n",
    "\n",
    "#dataset = datasets.ImageFolder('traindata/',transform=None)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "train_dataset, val_dataset = data.random_split(dataset, [train_len, valid_len])\n",
    "train_dataset=TVDataset(train_dataset,transform)\n",
    "val_dataset=TVDataset(val_dataset,transform1)\n",
    "\n",
    "train_data_loader = torch.utils.data.DataLoader(train_dataset, batch_size=32, shuffle=True) \n",
    "val_data_loader = torch.utils.data.DataLoader(val_dataset, batch_size=32, shuffle=False) \n",
    "#transformed_dataset = datasets.ImageFolder('traindata/', transform=transform)\n",
    "#dataset = torch.utils.data.ConcatDataset([transformed_dataset,origin_dataset])\n",
    "#dataloader = torch.utils.data.DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "#,transforms.RandomCrop((50,50))  \n",
    "#transforms.Normalize(mean = (0.5, 0.5, 0.5), std = (0.5, 0.5, 0.5)),\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "image,label=next(iter(val_data_loader))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function Tensor.mode>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image.mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "n=1\n",
    "#plt.imshow((np.transpose(image[n].numpy(), (1, 2, 0)).squeeze()* 255).astype('uint8'))\n",
    "print(label[n])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train & Valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I have written the function for you this time, but it's strongly recommended that you \n",
    "# understand how to do training and validation\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "def train(model, data_loader, optimizer, epoch,scheduler, verbose=True):\n",
    "    model.train()\n",
    "    loss_avg = 0.0\n",
    "    for batch_idx, (data, target) in enumerate(data_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        \n",
    "        output = model(data)\n",
    "        \n",
    "        # loss function\n",
    "        criterion  = nn.CrossEntropyLoss()\n",
    "        loss   = criterion (output, target)\n",
    "        loss_avg += loss.item()\n",
    "        \n",
    "        # do back propagation\n",
    "        optimizer.zero_grad() \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        \n",
    "        #print\n",
    "        #verbose_step = len(data_loader) // 10\n",
    "        verbose_step=100\n",
    "        if batch_idx % verbose_step == 0 and verbose:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(data_loader.dataset),\n",
    "                100. * batch_idx / len(data_loader), loss.item()))\n",
    "    return loss_avg / len(data_loader)\n",
    "\n",
    "def valid(model, data_loader):\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        valid_loss = 0\n",
    "        correct = 0\n",
    "        for data, target in data_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            #00\n",
    "            criterion  = nn.CrossEntropyLoss()\n",
    "            loss   = criterion (output, target)\n",
    "            loss_avg = loss.item()\n",
    "            valid_loss +=loss_avg  # sum up batch loss\n",
    "            pred = output.data.max(1, keepdim=True)[1] # get the index of the max log-probability\n",
    "            correct += pred.eq(target.data.view_as(pred)).cpu().sum().item() \n",
    "\n",
    "        #valid_loss /= len(data_loader.dataset)\n",
    "        valid_loss /= len(data_loader)\n",
    "        print('Valid set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "            valid_loss, correct, len(data_loader.dataset),\n",
    "            100. * correct / len(data_loader.dataset)))\n",
    "    return float(correct) / len(data_loader.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=resnet18(3,6)\n",
    "model.to(device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0 [0/10451 (0%)]\tLoss: 1.788399\n",
      "Train Epoch: 0 [3200/10451 (31%)]\tLoss: 1.670528\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/NFS/course/mlintro/mlintro2021s/mlintro2021s21/.local/lib/python3.6/site-packages/PIL/TiffImagePlugin.py:747: UserWarning: Possibly corrupt EXIF data.  Expecting to read 80000 bytes but only got 0. Skipping tag 64640\n",
      "  \" Skipping tag %s\" % (size, len(data), tag))\n",
      "/home/NFS/course/mlintro/mlintro2021s/mlintro2021s21/.local/lib/python3.6/site-packages/PIL/TiffImagePlugin.py:747: UserWarning: Possibly corrupt EXIF data.  Expecting to read 6553600 bytes but only got 0. Skipping tag 49\n",
      "  \" Skipping tag %s\" % (size, len(data), tag))\n",
      "/home/NFS/course/mlintro/mlintro2021s/mlintro2021s21/.local/lib/python3.6/site-packages/PIL/TiffImagePlugin.py:747: UserWarning: Possibly corrupt EXIF data.  Expecting to read 1050744 bytes but only got 4951. Skipping tag 51\n",
      "  \" Skipping tag %s\" % (size, len(data), tag))\n",
      "/home/NFS/course/mlintro/mlintro2021s/mlintro2021s21/.local/lib/python3.6/site-packages/PIL/TiffImagePlugin.py:747: UserWarning: Possibly corrupt EXIF data.  Expecting to read 293339136 bytes but only got 0. Skipping tag 5\n",
      "  \" Skipping tag %s\" % (size, len(data), tag))\n",
      "/home/NFS/course/mlintro/mlintro2021s/mlintro2021s21/.local/lib/python3.6/site-packages/PIL/TiffImagePlugin.py:747: UserWarning: Possibly corrupt EXIF data.  Expecting to read 293863424 bytes but only got 0. Skipping tag 5\n",
      "  \" Skipping tag %s\" % (size, len(data), tag))\n",
      "/home/NFS/course/mlintro/mlintro2021s/mlintro2021s21/.local/lib/python3.6/site-packages/PIL/TiffImagePlugin.py:747: UserWarning: Possibly corrupt EXIF data.  Expecting to read 3368026112 bytes but only got 0. Skipping tag 7\n",
      "  \" Skipping tag %s\" % (size, len(data), tag))\n",
      "/home/NFS/course/mlintro/mlintro2021s/mlintro2021s21/.local/lib/python3.6/site-packages/PIL/TiffImagePlugin.py:747: UserWarning: Possibly corrupt EXIF data.  Expecting to read 134479872 bytes but only got 0. Skipping tag 7\n",
      "  \" Skipping tag %s\" % (size, len(data), tag))\n",
      "/home/NFS/course/mlintro/mlintro2021s/mlintro2021s21/.local/lib/python3.6/site-packages/PIL/TiffImagePlugin.py:747: UserWarning: Possibly corrupt EXIF data.  Expecting to read 295698432 bytes but only got 0. Skipping tag 10\n",
      "  \" Skipping tag %s\" % (size, len(data), tag))\n",
      "/home/NFS/course/mlintro/mlintro2021s/mlintro2021s21/.local/lib/python3.6/site-packages/PIL/TiffImagePlugin.py:747: UserWarning: Possibly corrupt EXIF data.  Expecting to read 296222720 bytes but only got 0. Skipping tag 5\n",
      "  \" Skipping tag %s\" % (size, len(data), tag))\n",
      "/home/NFS/course/mlintro/mlintro2021s/mlintro2021s21/.local/lib/python3.6/site-packages/PIL/TiffImagePlugin.py:747: UserWarning: Possibly corrupt EXIF data.  Expecting to read 3300917248 bytes but only got 0. Skipping tag 7\n",
      "  \" Skipping tag %s\" % (size, len(data), tag))\n",
      "/home/NFS/course/mlintro/mlintro2021s/mlintro2021s21/.local/lib/python3.6/site-packages/PIL/TiffImagePlugin.py:747: UserWarning: Possibly corrupt EXIF data.  Expecting to read 65536 bytes but only got 0. Skipping tag 3\n",
      "  \" Skipping tag %s\" % (size, len(data), tag))\n",
      "/home/NFS/course/mlintro/mlintro2021s/mlintro2021s21/.local/lib/python3.6/site-packages/PIL/TiffImagePlugin.py:747: UserWarning: Possibly corrupt EXIF data.  Expecting to read 14745600 bytes but only got 0. Skipping tag 4\n",
      "  \" Skipping tag %s\" % (size, len(data), tag))\n",
      "/home/NFS/course/mlintro/mlintro2021s/mlintro2021s21/.local/lib/python3.6/site-packages/PIL/TiffImagePlugin.py:747: UserWarning: Possibly corrupt EXIF data.  Expecting to read 25624576 bytes but only got 0. Skipping tag 4\n",
      "  \" Skipping tag %s\" % (size, len(data), tag))\n",
      "/home/NFS/course/mlintro/mlintro2021s/mlintro2021s21/.local/lib/python3.6/site-packages/PIL/TiffImagePlugin.py:747: UserWarning: Possibly corrupt EXIF data.  Expecting to read 317718528 bytes but only got 4956. Skipping tag 4\n",
      "  \" Skipping tag %s\" % (size, len(data), tag))\n",
      "/home/NFS/course/mlintro/mlintro2021s/mlintro2021s21/.local/lib/python3.6/site-packages/PIL/TiffImagePlugin.py:747: UserWarning: Possibly corrupt EXIF data.  Expecting to read 131073 bytes but only got 4952. Skipping tag 0\n",
      "  \" Skipping tag %s\" % (size, len(data), tag))\n",
      "/home/NFS/course/mlintro/mlintro2021s/mlintro2021s21/.local/lib/python3.6/site-packages/PIL/TiffImagePlugin.py:747: UserWarning: Possibly corrupt EXIF data.  Expecting to read 393216 bytes but only got 0. Skipping tag 3\n",
      "  \" Skipping tag %s\" % (size, len(data), tag))\n",
      "/home/NFS/course/mlintro/mlintro2021s/mlintro2021s21/.local/lib/python3.6/site-packages/PIL/TiffImagePlugin.py:747: UserWarning: Possibly corrupt EXIF data.  Expecting to read 287178752 bytes but only got 0. Skipping tag 5\n",
      "  \" Skipping tag %s\" % (size, len(data), tag))\n",
      "/home/NFS/course/mlintro/mlintro2021s/mlintro2021s21/.local/lib/python3.6/site-packages/PIL/TiffImagePlugin.py:747: UserWarning: Possibly corrupt EXIF data.  Expecting to read 287703040 bytes but only got 0. Skipping tag 5\n",
      "  \" Skipping tag %s\" % (size, len(data), tag))\n",
      "/home/NFS/course/mlintro/mlintro2021s/mlintro2021s21/.local/lib/python3.6/site-packages/PIL/TiffImagePlugin.py:747: UserWarning: Possibly corrupt EXIF data.  Expecting to read 131072 bytes but only got 0. Skipping tag 3\n",
      "  \" Skipping tag %s\" % (size, len(data), tag))\n",
      "/home/NFS/course/mlintro/mlintro2021s/mlintro2021s21/.local/lib/python3.6/site-packages/PIL/TiffImagePlugin.py:747: UserWarning: Possibly corrupt EXIF data.  Expecting to read 524288 bytes but only got 0. Skipping tag 4\n",
      "  \" Skipping tag %s\" % (size, len(data), tag))\n",
      "/home/NFS/course/mlintro/mlintro2021s/mlintro2021s21/.local/lib/python3.6/site-packages/PIL/TiffImagePlugin.py:747: UserWarning: Possibly corrupt EXIF data.  Expecting to read 286654464 bytes but only got 4956. Skipping tag 4\n",
      "  \" Skipping tag %s\" % (size, len(data), tag))\n",
      "/home/NFS/course/mlintro/mlintro2021s/mlintro2021s21/.local/lib/python3.6/site-packages/PIL/TiffImagePlugin.py:764: UserWarning: Corrupt EXIF data.  Expecting to read 12 bytes but only got 2. \n",
      "  warnings.warn(str(msg))\n",
      "/home/NFS/course/mlintro/mlintro2021s/mlintro2021s21/.local/lib/python3.6/site-packages/PIL/TiffImagePlugin.py:747: UserWarning: Possibly corrupt EXIF data.  Expecting to read 404094976 bytes but only got 0. Skipping tag 5\n",
      "  \" Skipping tag %s\" % (size, len(data), tag))\n",
      "/home/NFS/course/mlintro/mlintro2021s/mlintro2021s21/.local/lib/python3.6/site-packages/PIL/TiffImagePlugin.py:747: UserWarning: Possibly corrupt EXIF data.  Expecting to read 404619264 bytes but only got 0. Skipping tag 5\n",
      "  \" Skipping tag %s\" % (size, len(data), tag))\n",
      "/home/NFS/course/mlintro/mlintro2021s/mlintro2021s21/.local/lib/python3.6/site-packages/PIL/TiffImagePlugin.py:747: UserWarning: Possibly corrupt EXIF data.  Expecting to read 425459712 bytes but only got 0. Skipping tag 4\n",
      "  \" Skipping tag %s\" % (size, len(data), tag))\n",
      "/home/NFS/course/mlintro/mlintro2021s/mlintro2021s21/.local/lib/python3.6/site-packages/PIL/TiffImagePlugin.py:747: UserWarning: Possibly corrupt EXIF data.  Expecting to read 1385474 bytes but only got 6833. Skipping tag 513\n",
      "  \" Skipping tag %s\" % (size, len(data), tag))\n",
      "/home/NFS/course/mlintro/mlintro2021s/mlintro2021s21/.local/lib/python3.6/site-packages/PIL/TiffImagePlugin.py:747: UserWarning: Possibly corrupt EXIF data.  Expecting to read 3846701056 bytes but only got 0. Skipping tag 2\n",
      "  \" Skipping tag %s\" % (size, len(data), tag))\n",
      "/home/NFS/course/mlintro/mlintro2021s/mlintro2021s21/.local/lib/python3.6/site-packages/PIL/TiffImagePlugin.py:747: UserWarning: Possibly corrupt EXIF data.  Expecting to read 196867 bytes but only got 6833. Skipping tag 0\n",
      "  \" Skipping tag %s\" % (size, len(data), tag))\n",
      "/home/NFS/course/mlintro/mlintro2021s/mlintro2021s21/.local/lib/python3.6/site-packages/PIL/TiffImagePlugin.py:764: UserWarning: Corrupt EXIF data.  Expecting to read 12 bytes but only got 8. \n",
      "  warnings.warn(str(msg))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0 [6400/10451 (61%)]\tLoss: 1.628653\n",
      "Train Epoch: 0 [9600/10451 (92%)]\tLoss: 1.470517\n",
      "-> Train Epoch: 0 \tLoss: 1.584734\n",
      "Valid set: Average loss: 1.5932, Accuracy: 948/2613 (36%)\n",
      "\n",
      "Train Epoch: 1 [0/10451 (0%)]\tLoss: 1.393530\n",
      "Train Epoch: 1 [3200/10451 (31%)]\tLoss: 1.449840\n",
      "Train Epoch: 1 [6400/10451 (61%)]\tLoss: 1.657221\n",
      "Train Epoch: 1 [9600/10451 (92%)]\tLoss: 1.368242\n",
      "-> Train Epoch: 1 \tLoss: 1.453207\n",
      "Valid set: Average loss: 1.5510, Accuracy: 1000/2613 (38%)\n",
      "\n",
      "Train Epoch: 2 [0/10451 (0%)]\tLoss: 1.599807\n",
      "Train Epoch: 2 [3200/10451 (31%)]\tLoss: 1.439816\n",
      "Train Epoch: 2 [6400/10451 (61%)]\tLoss: 1.391903\n",
      "Train Epoch: 2 [9600/10451 (92%)]\tLoss: 1.147650\n",
      "-> Train Epoch: 2 \tLoss: 1.361415\n",
      "Valid set: Average loss: 1.4287, Accuracy: 1093/2613 (42%)\n",
      "\n",
      "Train Epoch: 3 [0/10451 (0%)]\tLoss: 1.331752\n",
      "Train Epoch: 3 [3200/10451 (31%)]\tLoss: 1.183051\n",
      "Train Epoch: 3 [6400/10451 (61%)]\tLoss: 1.370685\n",
      "Train Epoch: 3 [9600/10451 (92%)]\tLoss: 1.362253\n",
      "-> Train Epoch: 3 \tLoss: 1.295260\n",
      "Valid set: Average loss: 1.3841, Accuracy: 1154/2613 (44%)\n",
      "\n",
      "Train Epoch: 4 [0/10451 (0%)]\tLoss: 1.182660\n",
      "Train Epoch: 4 [3200/10451 (31%)]\tLoss: 1.317700\n",
      "Train Epoch: 4 [6400/10451 (61%)]\tLoss: 1.057470\n",
      "Train Epoch: 4 [9600/10451 (92%)]\tLoss: 1.189355\n",
      "-> Train Epoch: 4 \tLoss: 1.234500\n",
      "Valid set: Average loss: 1.2782, Accuracy: 1247/2613 (48%)\n",
      "\n",
      "Train Epoch: 5 [0/10451 (0%)]\tLoss: 1.093104\n",
      "Train Epoch: 5 [3200/10451 (31%)]\tLoss: 1.206378\n",
      "Train Epoch: 5 [6400/10451 (61%)]\tLoss: 0.894769\n",
      "Train Epoch: 5 [9600/10451 (92%)]\tLoss: 1.579754\n",
      "-> Train Epoch: 5 \tLoss: 1.190743\n",
      "Valid set: Average loss: 1.3664, Accuracy: 1183/2613 (45%)\n",
      "\n",
      "Train Epoch: 6 [0/10451 (0%)]\tLoss: 1.494374\n",
      "Train Epoch: 6 [3200/10451 (31%)]\tLoss: 1.274776\n",
      "Train Epoch: 6 [6400/10451 (61%)]\tLoss: 0.996740\n",
      "Train Epoch: 6 [9600/10451 (92%)]\tLoss: 1.412095\n",
      "-> Train Epoch: 6 \tLoss: 1.126680\n",
      "Valid set: Average loss: 1.2598, Accuracy: 1282/2613 (49%)\n",
      "\n",
      "Train Epoch: 7 [0/10451 (0%)]\tLoss: 1.043642\n",
      "Train Epoch: 7 [3200/10451 (31%)]\tLoss: 1.422194\n",
      "Train Epoch: 7 [6400/10451 (61%)]\tLoss: 1.132703\n",
      "Train Epoch: 7 [9600/10451 (92%)]\tLoss: 1.147982\n",
      "-> Train Epoch: 7 \tLoss: 1.086734\n",
      "Valid set: Average loss: 1.3102, Accuracy: 1225/2613 (47%)\n",
      "\n",
      "Train Epoch: 8 [0/10451 (0%)]\tLoss: 1.209018\n",
      "Train Epoch: 8 [3200/10451 (31%)]\tLoss: 1.054562\n",
      "Train Epoch: 8 [6400/10451 (61%)]\tLoss: 0.999191\n",
      "Train Epoch: 8 [9600/10451 (92%)]\tLoss: 1.063080\n",
      "-> Train Epoch: 8 \tLoss: 1.068088\n",
      "Valid set: Average loss: 1.2867, Accuracy: 1242/2613 (48%)\n",
      "\n",
      "Train Epoch: 9 [0/10451 (0%)]\tLoss: 1.125106\n",
      "Train Epoch: 9 [3200/10451 (31%)]\tLoss: 1.091285\n",
      "Train Epoch: 9 [6400/10451 (61%)]\tLoss: 1.243022\n",
      "Train Epoch: 9 [9600/10451 (92%)]\tLoss: 0.785932\n",
      "-> Train Epoch: 9 \tLoss: 1.032659\n",
      "Valid set: Average loss: 1.1881, Accuracy: 1380/2613 (53%)\n",
      "\n",
      "Train Epoch: 10 [0/10451 (0%)]\tLoss: 1.164900\n",
      "Train Epoch: 10 [3200/10451 (31%)]\tLoss: 0.977696\n",
      "Train Epoch: 10 [6400/10451 (61%)]\tLoss: 0.924060\n",
      "Train Epoch: 10 [9600/10451 (92%)]\tLoss: 1.117355\n",
      "-> Train Epoch: 10 \tLoss: 1.009314\n",
      "Valid set: Average loss: 1.2118, Accuracy: 1331/2613 (51%)\n",
      "\n",
      "Train Epoch: 11 [0/10451 (0%)]\tLoss: 0.812730\n",
      "Train Epoch: 11 [3200/10451 (31%)]\tLoss: 0.883379\n",
      "Train Epoch: 11 [6400/10451 (61%)]\tLoss: 0.952068\n",
      "Train Epoch: 11 [9600/10451 (92%)]\tLoss: 1.008912\n",
      "-> Train Epoch: 11 \tLoss: 0.993975\n",
      "Valid set: Average loss: 1.2000, Accuracy: 1392/2613 (53%)\n",
      "\n",
      "Train Epoch: 12 [0/10451 (0%)]\tLoss: 0.960165\n",
      "Train Epoch: 12 [3200/10451 (31%)]\tLoss: 1.153811\n",
      "Train Epoch: 12 [6400/10451 (61%)]\tLoss: 0.749025\n",
      "Train Epoch: 12 [9600/10451 (92%)]\tLoss: 0.829317\n",
      "-> Train Epoch: 12 \tLoss: 0.973684\n",
      "Valid set: Average loss: 1.1975, Accuracy: 1377/2613 (53%)\n",
      "\n",
      "Train Epoch: 13 [0/10451 (0%)]\tLoss: 0.743740\n",
      "Train Epoch: 13 [3200/10451 (31%)]\tLoss: 0.820009\n",
      "Train Epoch: 13 [6400/10451 (61%)]\tLoss: 0.763627\n",
      "Train Epoch: 13 [9600/10451 (92%)]\tLoss: 1.054374\n",
      "-> Train Epoch: 13 \tLoss: 0.951703\n",
      "Valid set: Average loss: 1.1621, Accuracy: 1372/2613 (53%)\n",
      "\n",
      "Train Epoch: 14 [0/10451 (0%)]\tLoss: 0.868334\n",
      "Train Epoch: 14 [3200/10451 (31%)]\tLoss: 0.628232\n",
      "Train Epoch: 14 [6400/10451 (61%)]\tLoss: 1.014756\n",
      "Train Epoch: 14 [9600/10451 (92%)]\tLoss: 1.100098\n",
      "-> Train Epoch: 14 \tLoss: 0.922719\n",
      "Valid set: Average loss: 1.1696, Accuracy: 1401/2613 (54%)\n",
      "\n",
      "Train Epoch: 15 [0/10451 (0%)]\tLoss: 0.909921\n",
      "Train Epoch: 15 [3200/10451 (31%)]\tLoss: 0.842003\n",
      "Train Epoch: 15 [6400/10451 (61%)]\tLoss: 0.753034\n",
      "Train Epoch: 15 [9600/10451 (92%)]\tLoss: 0.842085\n",
      "-> Train Epoch: 15 \tLoss: 0.904902\n",
      "Valid set: Average loss: 1.1161, Accuracy: 1484/2613 (57%)\n",
      "\n",
      "Train Epoch: 16 [0/10451 (0%)]\tLoss: 0.860551\n",
      "Train Epoch: 16 [3200/10451 (31%)]\tLoss: 0.880274\n",
      "Train Epoch: 16 [6400/10451 (61%)]\tLoss: 1.084886\n",
      "Train Epoch: 16 [9600/10451 (92%)]\tLoss: 0.880897\n",
      "-> Train Epoch: 16 \tLoss: 0.884649\n",
      "Valid set: Average loss: 1.1629, Accuracy: 1454/2613 (56%)\n",
      "\n",
      "Train Epoch: 17 [0/10451 (0%)]\tLoss: 1.015548\n",
      "Train Epoch: 17 [3200/10451 (31%)]\tLoss: 0.921365\n",
      "Train Epoch: 17 [6400/10451 (61%)]\tLoss: 0.812357\n",
      "Train Epoch: 17 [9600/10451 (92%)]\tLoss: 0.837738\n",
      "-> Train Epoch: 17 \tLoss: 0.872459\n",
      "Valid set: Average loss: 1.1123, Accuracy: 1470/2613 (56%)\n",
      "\n",
      "Train Epoch: 18 [0/10451 (0%)]\tLoss: 0.829394\n",
      "Train Epoch: 18 [3200/10451 (31%)]\tLoss: 1.135955\n",
      "Train Epoch: 18 [6400/10451 (61%)]\tLoss: 0.620645\n",
      "Train Epoch: 18 [9600/10451 (92%)]\tLoss: 0.868787\n",
      "-> Train Epoch: 18 \tLoss: 0.849823\n",
      "Valid set: Average loss: 1.1921, Accuracy: 1405/2613 (54%)\n",
      "\n",
      "Train Epoch: 19 [0/10451 (0%)]\tLoss: 0.714323\n",
      "Train Epoch: 19 [3200/10451 (31%)]\tLoss: 0.947476\n",
      "Train Epoch: 19 [6400/10451 (61%)]\tLoss: 0.852962\n",
      "Train Epoch: 19 [9600/10451 (92%)]\tLoss: 0.784405\n",
      "-> Train Epoch: 19 \tLoss: 0.827505\n",
      "Valid set: Average loss: 1.0488, Accuracy: 1578/2613 (60%)\n",
      "\n",
      "Train Epoch: 20 [0/10451 (0%)]\tLoss: 0.892149\n",
      "Train Epoch: 20 [3200/10451 (31%)]\tLoss: 0.857948\n",
      "Train Epoch: 20 [6400/10451 (61%)]\tLoss: 0.652578\n",
      "Train Epoch: 20 [9600/10451 (92%)]\tLoss: 0.591434\n",
      "-> Train Epoch: 20 \tLoss: 0.805751\n",
      "Valid set: Average loss: 1.0363, Accuracy: 1556/2613 (60%)\n",
      "\n",
      "Train Epoch: 21 [0/10451 (0%)]\tLoss: 0.816058\n",
      "Train Epoch: 21 [3200/10451 (31%)]\tLoss: 0.866720\n",
      "Train Epoch: 21 [6400/10451 (61%)]\tLoss: 0.825116\n",
      "Train Epoch: 21 [9600/10451 (92%)]\tLoss: 0.940264\n",
      "-> Train Epoch: 21 \tLoss: 0.794355\n",
      "Valid set: Average loss: 0.9924, Accuracy: 1645/2613 (63%)\n",
      "\n",
      "Train Epoch: 22 [0/10451 (0%)]\tLoss: 0.681881\n",
      "Train Epoch: 22 [3200/10451 (31%)]\tLoss: 0.987794\n",
      "Train Epoch: 22 [6400/10451 (61%)]\tLoss: 0.749760\n",
      "Train Epoch: 22 [9600/10451 (92%)]\tLoss: 0.636932\n",
      "-> Train Epoch: 22 \tLoss: 0.773793\n",
      "Valid set: Average loss: 1.2433, Accuracy: 1447/2613 (55%)\n",
      "\n",
      "Train Epoch: 23 [0/10451 (0%)]\tLoss: 0.843039\n",
      "Train Epoch: 23 [3200/10451 (31%)]\tLoss: 0.640901\n",
      "Train Epoch: 23 [6400/10451 (61%)]\tLoss: 0.710290\n",
      "Train Epoch: 23 [9600/10451 (92%)]\tLoss: 0.946492\n",
      "-> Train Epoch: 23 \tLoss: 0.751438\n",
      "Valid set: Average loss: 0.9936, Accuracy: 1629/2613 (62%)\n",
      "\n",
      "Train Epoch: 24 [0/10451 (0%)]\tLoss: 0.478322\n",
      "Train Epoch: 24 [3200/10451 (31%)]\tLoss: 1.010239\n",
      "Train Epoch: 24 [6400/10451 (61%)]\tLoss: 0.401095\n",
      "Train Epoch: 24 [9600/10451 (92%)]\tLoss: 0.476730\n",
      "-> Train Epoch: 24 \tLoss: 0.745242\n",
      "Valid set: Average loss: 1.0030, Accuracy: 1632/2613 (62%)\n",
      "\n",
      "Train Epoch: 25 [0/10451 (0%)]\tLoss: 0.642238\n",
      "Train Epoch: 25 [3200/10451 (31%)]\tLoss: 0.846471\n",
      "Train Epoch: 25 [6400/10451 (61%)]\tLoss: 0.764896\n",
      "Train Epoch: 25 [9600/10451 (92%)]\tLoss: 1.006458\n",
      "-> Train Epoch: 25 \tLoss: 0.725527\n",
      "Valid set: Average loss: 0.9897, Accuracy: 1639/2613 (63%)\n",
      "\n",
      "Train Epoch: 26 [0/10451 (0%)]\tLoss: 1.109585\n",
      "Train Epoch: 26 [3200/10451 (31%)]\tLoss: 0.547269\n",
      "Train Epoch: 26 [6400/10451 (61%)]\tLoss: 0.902791\n",
      "Train Epoch: 26 [9600/10451 (92%)]\tLoss: 0.811501\n",
      "-> Train Epoch: 26 \tLoss: 0.714383\n",
      "Valid set: Average loss: 1.0068, Accuracy: 1654/2613 (63%)\n",
      "\n",
      "Train Epoch: 27 [0/10451 (0%)]\tLoss: 0.582047\n",
      "Train Epoch: 27 [3200/10451 (31%)]\tLoss: 0.778426\n",
      "Train Epoch: 27 [6400/10451 (61%)]\tLoss: 0.519082\n",
      "Train Epoch: 27 [9600/10451 (92%)]\tLoss: 0.623559\n",
      "-> Train Epoch: 27 \tLoss: 0.707114\n",
      "Valid set: Average loss: 1.0027, Accuracy: 1623/2613 (62%)\n",
      "\n",
      "Train Epoch: 28 [0/10451 (0%)]\tLoss: 1.141044\n",
      "Train Epoch: 28 [3200/10451 (31%)]\tLoss: 0.578996\n",
      "Train Epoch: 28 [6400/10451 (61%)]\tLoss: 0.701927\n",
      "Train Epoch: 28 [9600/10451 (92%)]\tLoss: 0.653714\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Train Epoch: 28 \tLoss: 0.692832\n",
      "Valid set: Average loss: 1.0240, Accuracy: 1635/2613 (63%)\n",
      "\n",
      "Train Epoch: 29 [0/10451 (0%)]\tLoss: 0.512225\n",
      "Train Epoch: 29 [3200/10451 (31%)]\tLoss: 0.864634\n",
      "Train Epoch: 29 [6400/10451 (61%)]\tLoss: 0.547598\n",
      "Train Epoch: 29 [9600/10451 (92%)]\tLoss: 0.690355\n",
      "-> Train Epoch: 29 \tLoss: 0.677227\n",
      "Valid set: Average loss: 0.9876, Accuracy: 1685/2613 (64%)\n",
      "\n",
      "Train Epoch: 30 [0/10451 (0%)]\tLoss: 0.726129\n",
      "Train Epoch: 30 [3200/10451 (31%)]\tLoss: 0.611961\n",
      "Train Epoch: 30 [6400/10451 (61%)]\tLoss: 0.696621\n",
      "Train Epoch: 30 [9600/10451 (92%)]\tLoss: 0.696360\n",
      "-> Train Epoch: 30 \tLoss: 0.662391\n",
      "Valid set: Average loss: 0.9834, Accuracy: 1671/2613 (64%)\n",
      "\n",
      "Train Epoch: 31 [0/10451 (0%)]\tLoss: 0.527964\n",
      "Train Epoch: 31 [3200/10451 (31%)]\tLoss: 0.730242\n",
      "Train Epoch: 31 [6400/10451 (61%)]\tLoss: 0.615253\n",
      "Train Epoch: 31 [9600/10451 (92%)]\tLoss: 0.778864\n",
      "-> Train Epoch: 31 \tLoss: 0.662459\n",
      "Valid set: Average loss: 0.9826, Accuracy: 1646/2613 (63%)\n",
      "\n",
      "Train Epoch: 32 [0/10451 (0%)]\tLoss: 0.524453\n",
      "Train Epoch: 32 [3200/10451 (31%)]\tLoss: 0.516648\n",
      "Train Epoch: 32 [6400/10451 (61%)]\tLoss: 0.871311\n",
      "Train Epoch: 32 [9600/10451 (92%)]\tLoss: 0.714770\n",
      "-> Train Epoch: 32 \tLoss: 0.641047\n",
      "Valid set: Average loss: 0.9848, Accuracy: 1645/2613 (63%)\n",
      "\n",
      "Train Epoch: 33 [0/10451 (0%)]\tLoss: 0.743420\n",
      "Train Epoch: 33 [3200/10451 (31%)]\tLoss: 0.664679\n",
      "Train Epoch: 33 [6400/10451 (61%)]\tLoss: 0.611638\n",
      "Train Epoch: 33 [9600/10451 (92%)]\tLoss: 0.590574\n",
      "-> Train Epoch: 33 \tLoss: 0.638945\n",
      "Valid set: Average loss: 0.9590, Accuracy: 1657/2613 (63%)\n",
      "\n",
      "Train Epoch: 34 [0/10451 (0%)]\tLoss: 0.915841\n",
      "Train Epoch: 34 [3200/10451 (31%)]\tLoss: 0.660157\n",
      "Train Epoch: 34 [6400/10451 (61%)]\tLoss: 0.958078\n",
      "Train Epoch: 34 [9600/10451 (92%)]\tLoss: 0.603128\n",
      "-> Train Epoch: 34 \tLoss: 0.624586\n",
      "Valid set: Average loss: 0.9699, Accuracy: 1682/2613 (64%)\n",
      "\n",
      "Train Epoch: 35 [0/10451 (0%)]\tLoss: 0.486737\n",
      "Train Epoch: 35 [3200/10451 (31%)]\tLoss: 0.492503\n",
      "Train Epoch: 35 [6400/10451 (61%)]\tLoss: 0.813227\n",
      "Train Epoch: 35 [9600/10451 (92%)]\tLoss: 0.541364\n",
      "-> Train Epoch: 35 \tLoss: 0.627074\n",
      "Valid set: Average loss: 0.9790, Accuracy: 1652/2613 (63%)\n",
      "\n",
      "Train Epoch: 36 [0/10451 (0%)]\tLoss: 0.836513\n",
      "Train Epoch: 36 [3200/10451 (31%)]\tLoss: 0.465815\n",
      "Train Epoch: 36 [6400/10451 (61%)]\tLoss: 0.762412\n",
      "Train Epoch: 36 [9600/10451 (92%)]\tLoss: 0.472448\n",
      "-> Train Epoch: 36 \tLoss: 0.600758\n",
      "Valid set: Average loss: 0.8944, Accuracy: 1730/2613 (66%)\n",
      "\n",
      "Train Epoch: 37 [0/10451 (0%)]\tLoss: 0.975822\n",
      "Train Epoch: 37 [3200/10451 (31%)]\tLoss: 0.788401\n",
      "Train Epoch: 37 [6400/10451 (61%)]\tLoss: 0.493090\n",
      "Train Epoch: 37 [9600/10451 (92%)]\tLoss: 0.624015\n",
      "-> Train Epoch: 37 \tLoss: 0.595876\n",
      "Valid set: Average loss: 0.8922, Accuracy: 1755/2613 (67%)\n",
      "\n",
      "Train Epoch: 38 [0/10451 (0%)]\tLoss: 0.268881\n",
      "Train Epoch: 38 [3200/10451 (31%)]\tLoss: 0.565160\n",
      "Train Epoch: 38 [6400/10451 (61%)]\tLoss: 0.702047\n",
      "Train Epoch: 38 [9600/10451 (92%)]\tLoss: 0.619218\n",
      "-> Train Epoch: 38 \tLoss: 0.586200\n",
      "Valid set: Average loss: 0.9010, Accuracy: 1749/2613 (67%)\n",
      "\n",
      "Train Epoch: 39 [0/10451 (0%)]\tLoss: 0.392797\n",
      "Train Epoch: 39 [3200/10451 (31%)]\tLoss: 0.505480\n",
      "Train Epoch: 39 [6400/10451 (61%)]\tLoss: 0.487218\n",
      "Train Epoch: 39 [9600/10451 (92%)]\tLoss: 0.482844\n",
      "-> Train Epoch: 39 \tLoss: 0.570569\n",
      "Valid set: Average loss: 0.9062, Accuracy: 1783/2613 (68%)\n",
      "\n",
      "Train Epoch: 40 [0/10451 (0%)]\tLoss: 0.638034\n",
      "Train Epoch: 40 [3200/10451 (31%)]\tLoss: 0.511437\n",
      "Train Epoch: 40 [6400/10451 (61%)]\tLoss: 0.483362\n",
      "Train Epoch: 40 [9600/10451 (92%)]\tLoss: 0.649298\n",
      "-> Train Epoch: 40 \tLoss: 0.573751\n",
      "Valid set: Average loss: 0.8825, Accuracy: 1784/2613 (68%)\n",
      "\n",
      "Train Epoch: 41 [0/10451 (0%)]\tLoss: 0.483259\n",
      "Train Epoch: 41 [3200/10451 (31%)]\tLoss: 0.725620\n",
      "Train Epoch: 41 [6400/10451 (61%)]\tLoss: 0.773482\n",
      "Train Epoch: 41 [9600/10451 (92%)]\tLoss: 0.756451\n",
      "-> Train Epoch: 41 \tLoss: 0.565616\n",
      "Valid set: Average loss: 0.8982, Accuracy: 1776/2613 (68%)\n",
      "\n",
      "Train Epoch: 42 [0/10451 (0%)]\tLoss: 0.751587\n",
      "Train Epoch: 42 [3200/10451 (31%)]\tLoss: 0.623098\n",
      "Train Epoch: 42 [6400/10451 (61%)]\tLoss: 0.327292\n",
      "Train Epoch: 42 [9600/10451 (92%)]\tLoss: 0.754491\n",
      "-> Train Epoch: 42 \tLoss: 0.550041\n",
      "Valid set: Average loss: 0.8583, Accuracy: 1798/2613 (69%)\n",
      "\n",
      "Train Epoch: 43 [0/10451 (0%)]\tLoss: 0.283583\n",
      "Train Epoch: 43 [3200/10451 (31%)]\tLoss: 0.611927\n",
      "Train Epoch: 43 [6400/10451 (61%)]\tLoss: 0.458923\n",
      "Train Epoch: 43 [9600/10451 (92%)]\tLoss: 0.497042\n",
      "-> Train Epoch: 43 \tLoss: 0.544693\n",
      "Valid set: Average loss: 0.8940, Accuracy: 1762/2613 (67%)\n",
      "\n",
      "Train Epoch: 44 [0/10451 (0%)]\tLoss: 0.400364\n",
      "Train Epoch: 44 [3200/10451 (31%)]\tLoss: 0.366016\n",
      "Train Epoch: 44 [6400/10451 (61%)]\tLoss: 0.512253\n",
      "Train Epoch: 44 [9600/10451 (92%)]\tLoss: 0.442613\n",
      "-> Train Epoch: 44 \tLoss: 0.528997\n",
      "Valid set: Average loss: 0.8310, Accuracy: 1794/2613 (69%)\n",
      "\n",
      "Train Epoch: 45 [0/10451 (0%)]\tLoss: 0.413312\n",
      "Train Epoch: 45 [3200/10451 (31%)]\tLoss: 0.580667\n",
      "Train Epoch: 45 [6400/10451 (61%)]\tLoss: 0.913619\n",
      "Train Epoch: 45 [9600/10451 (92%)]\tLoss: 0.662776\n",
      "-> Train Epoch: 45 \tLoss: 0.540635\n",
      "Valid set: Average loss: 0.8934, Accuracy: 1766/2613 (68%)\n",
      "\n",
      "Train Epoch: 46 [0/10451 (0%)]\tLoss: 0.327222\n",
      "Train Epoch: 46 [3200/10451 (31%)]\tLoss: 0.267765\n",
      "Train Epoch: 46 [6400/10451 (61%)]\tLoss: 0.466389\n",
      "Train Epoch: 46 [9600/10451 (92%)]\tLoss: 0.564400\n",
      "-> Train Epoch: 46 \tLoss: 0.532455\n",
      "Valid set: Average loss: 0.9197, Accuracy: 1777/2613 (68%)\n",
      "\n",
      "Train Epoch: 47 [0/10451 (0%)]\tLoss: 0.765171\n",
      "Train Epoch: 47 [3200/10451 (31%)]\tLoss: 0.511213\n",
      "Train Epoch: 47 [6400/10451 (61%)]\tLoss: 0.377133\n",
      "Train Epoch: 47 [9600/10451 (92%)]\tLoss: 0.632980\n",
      "-> Train Epoch: 47 \tLoss: 0.515542\n",
      "Valid set: Average loss: 0.8622, Accuracy: 1787/2613 (68%)\n",
      "\n",
      "Train Epoch: 48 [0/10451 (0%)]\tLoss: 0.581112\n",
      "Train Epoch: 48 [3200/10451 (31%)]\tLoss: 0.310661\n",
      "Train Epoch: 48 [6400/10451 (61%)]\tLoss: 0.328502\n",
      "Train Epoch: 48 [9600/10451 (92%)]\tLoss: 0.320766\n",
      "-> Train Epoch: 48 \tLoss: 0.501626\n",
      "Valid set: Average loss: 0.8961, Accuracy: 1768/2613 (68%)\n",
      "\n",
      "Train Epoch: 49 [0/10451 (0%)]\tLoss: 0.821094\n",
      "Train Epoch: 49 [3200/10451 (31%)]\tLoss: 0.469050\n",
      "Train Epoch: 49 [6400/10451 (61%)]\tLoss: 0.563772\n",
      "Train Epoch: 49 [9600/10451 (92%)]\tLoss: 0.712721\n",
      "-> Train Epoch: 49 \tLoss: 0.494404\n",
      "Valid set: Average loss: 0.8671, Accuracy: 1820/2613 (70%)\n",
      "\n",
      "Train Epoch: 50 [0/10451 (0%)]\tLoss: 0.229291\n",
      "Train Epoch: 50 [3200/10451 (31%)]\tLoss: 0.445231\n",
      "Train Epoch: 50 [6400/10451 (61%)]\tLoss: 0.666329\n",
      "Train Epoch: 50 [9600/10451 (92%)]\tLoss: 0.440687\n",
      "-> Train Epoch: 50 \tLoss: 0.511180\n",
      "Valid set: Average loss: 0.8495, Accuracy: 1846/2613 (71%)\n",
      "\n",
      "Train Epoch: 51 [0/10451 (0%)]\tLoss: 0.493705\n",
      "Train Epoch: 51 [3200/10451 (31%)]\tLoss: 0.370628\n",
      "Train Epoch: 51 [6400/10451 (61%)]\tLoss: 0.442688\n",
      "Train Epoch: 51 [9600/10451 (92%)]\tLoss: 0.541393\n",
      "-> Train Epoch: 51 \tLoss: 0.491758\n",
      "Valid set: Average loss: 0.8958, Accuracy: 1797/2613 (69%)\n",
      "\n",
      "Train Epoch: 52 [0/10451 (0%)]\tLoss: 0.303261\n",
      "Train Epoch: 52 [3200/10451 (31%)]\tLoss: 0.638565\n",
      "Train Epoch: 52 [6400/10451 (61%)]\tLoss: 0.543186\n",
      "Train Epoch: 52 [9600/10451 (92%)]\tLoss: 0.450095\n",
      "-> Train Epoch: 52 \tLoss: 0.483736\n",
      "Valid set: Average loss: 0.8425, Accuracy: 1846/2613 (71%)\n",
      "\n",
      "Train Epoch: 53 [0/10451 (0%)]\tLoss: 0.447895\n",
      "Train Epoch: 53 [3200/10451 (31%)]\tLoss: 0.375271\n",
      "Train Epoch: 53 [6400/10451 (61%)]\tLoss: 0.350365\n",
      "Train Epoch: 53 [9600/10451 (92%)]\tLoss: 0.646323\n",
      "-> Train Epoch: 53 \tLoss: 0.474325\n",
      "Valid set: Average loss: 0.8203, Accuracy: 1864/2613 (71%)\n",
      "\n",
      "Train Epoch: 54 [0/10451 (0%)]\tLoss: 0.584625\n",
      "Train Epoch: 54 [3200/10451 (31%)]\tLoss: 0.394786\n",
      "Train Epoch: 54 [6400/10451 (61%)]\tLoss: 0.227800\n",
      "Train Epoch: 54 [9600/10451 (92%)]\tLoss: 0.314918\n",
      "-> Train Epoch: 54 \tLoss: 0.475334\n",
      "Valid set: Average loss: 0.8848, Accuracy: 1828/2613 (70%)\n",
      "\n",
      "Train Epoch: 55 [0/10451 (0%)]\tLoss: 0.273330\n",
      "Train Epoch: 55 [3200/10451 (31%)]\tLoss: 0.521318\n",
      "Train Epoch: 55 [6400/10451 (61%)]\tLoss: 0.666596\n",
      "Train Epoch: 55 [9600/10451 (92%)]\tLoss: 0.409464\n",
      "-> Train Epoch: 55 \tLoss: 0.468482\n",
      "Valid set: Average loss: 0.8475, Accuracy: 1843/2613 (71%)\n",
      "\n",
      "Train Epoch: 56 [0/10451 (0%)]\tLoss: 0.407349\n",
      "Train Epoch: 56 [3200/10451 (31%)]\tLoss: 0.498167\n",
      "Train Epoch: 56 [6400/10451 (61%)]\tLoss: 0.495002\n",
      "Train Epoch: 56 [9600/10451 (92%)]\tLoss: 0.211931\n",
      "-> Train Epoch: 56 \tLoss: 0.453855\n",
      "Valid set: Average loss: 0.8180, Accuracy: 1833/2613 (70%)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 57 [0/10451 (0%)]\tLoss: 0.307328\n",
      "Train Epoch: 57 [3200/10451 (31%)]\tLoss: 0.272944\n",
      "Train Epoch: 57 [6400/10451 (61%)]\tLoss: 0.594661\n",
      "Train Epoch: 57 [9600/10451 (92%)]\tLoss: 0.495173\n",
      "-> Train Epoch: 57 \tLoss: 0.455004\n",
      "Valid set: Average loss: 0.9072, Accuracy: 1808/2613 (69%)\n",
      "\n",
      "Train Epoch: 58 [0/10451 (0%)]\tLoss: 0.347437\n",
      "Train Epoch: 58 [3200/10451 (31%)]\tLoss: 0.521036\n",
      "Train Epoch: 58 [6400/10451 (61%)]\tLoss: 0.495522\n",
      "Train Epoch: 58 [9600/10451 (92%)]\tLoss: 0.547999\n",
      "-> Train Epoch: 58 \tLoss: 0.446191\n",
      "Valid set: Average loss: 0.8207, Accuracy: 1878/2613 (72%)\n",
      "\n",
      "Train Epoch: 59 [0/10451 (0%)]\tLoss: 0.320202\n",
      "Train Epoch: 59 [3200/10451 (31%)]\tLoss: 0.275495\n",
      "Train Epoch: 59 [6400/10451 (61%)]\tLoss: 0.629117\n",
      "Train Epoch: 59 [9600/10451 (92%)]\tLoss: 0.398884\n",
      "-> Train Epoch: 59 \tLoss: 0.443622\n",
      "Valid set: Average loss: 0.9150, Accuracy: 1821/2613 (70%)\n",
      "\n",
      "Train Epoch: 60 [0/10451 (0%)]\tLoss: 0.415683\n",
      "Train Epoch: 60 [3200/10451 (31%)]\tLoss: 0.491049\n",
      "Train Epoch: 60 [6400/10451 (61%)]\tLoss: 0.565076\n",
      "Train Epoch: 60 [9600/10451 (92%)]\tLoss: 0.494523\n",
      "-> Train Epoch: 60 \tLoss: 0.446042\n",
      "Valid set: Average loss: 0.7958, Accuracy: 1894/2613 (72%)\n",
      "\n",
      "Train Epoch: 61 [0/10451 (0%)]\tLoss: 0.417744\n",
      "Train Epoch: 61 [3200/10451 (31%)]\tLoss: 0.300411\n",
      "Train Epoch: 61 [6400/10451 (61%)]\tLoss: 0.396669\n",
      "Train Epoch: 61 [9600/10451 (92%)]\tLoss: 0.467802\n",
      "-> Train Epoch: 61 \tLoss: 0.435601\n",
      "Valid set: Average loss: 0.8250, Accuracy: 1849/2613 (71%)\n",
      "\n",
      "Train Epoch: 62 [0/10451 (0%)]\tLoss: 0.421599\n",
      "Train Epoch: 62 [3200/10451 (31%)]\tLoss: 0.373381\n",
      "Train Epoch: 62 [6400/10451 (61%)]\tLoss: 0.631505\n",
      "Train Epoch: 62 [9600/10451 (92%)]\tLoss: 0.318488\n",
      "-> Train Epoch: 62 \tLoss: 0.438310\n",
      "Valid set: Average loss: 0.8230, Accuracy: 1877/2613 (72%)\n",
      "\n",
      "Train Epoch: 63 [0/10451 (0%)]\tLoss: 0.369973\n",
      "Train Epoch: 63 [3200/10451 (31%)]\tLoss: 0.533601\n",
      "Train Epoch: 63 [6400/10451 (61%)]\tLoss: 0.301719\n",
      "Train Epoch: 63 [9600/10451 (92%)]\tLoss: 0.480466\n",
      "-> Train Epoch: 63 \tLoss: 0.430680\n",
      "Valid set: Average loss: 0.9571, Accuracy: 1788/2613 (68%)\n",
      "\n",
      "Train Epoch: 64 [0/10451 (0%)]\tLoss: 0.623144\n",
      "Train Epoch: 64 [3200/10451 (31%)]\tLoss: 0.501727\n",
      "Train Epoch: 64 [6400/10451 (61%)]\tLoss: 0.551126\n",
      "Train Epoch: 64 [9600/10451 (92%)]\tLoss: 0.313625\n",
      "-> Train Epoch: 64 \tLoss: 0.433414\n",
      "Valid set: Average loss: 0.7709, Accuracy: 1913/2613 (73%)\n",
      "\n",
      "Train Epoch: 65 [0/10451 (0%)]\tLoss: 0.540562\n",
      "Train Epoch: 65 [3200/10451 (31%)]\tLoss: 0.336360\n",
      "Train Epoch: 65 [6400/10451 (61%)]\tLoss: 0.391314\n",
      "Train Epoch: 65 [9600/10451 (92%)]\tLoss: 0.466145\n",
      "-> Train Epoch: 65 \tLoss: 0.424056\n",
      "Valid set: Average loss: 0.8269, Accuracy: 1864/2613 (71%)\n",
      "\n",
      "Train Epoch: 66 [0/10451 (0%)]\tLoss: 0.573327\n",
      "Train Epoch: 66 [3200/10451 (31%)]\tLoss: 0.488251\n",
      "Train Epoch: 66 [6400/10451 (61%)]\tLoss: 0.383215\n",
      "Train Epoch: 66 [9600/10451 (92%)]\tLoss: 0.531148\n",
      "-> Train Epoch: 66 \tLoss: 0.419688\n",
      "Valid set: Average loss: 0.8489, Accuracy: 1865/2613 (71%)\n",
      "\n",
      "Train Epoch: 67 [0/10451 (0%)]\tLoss: 0.335470\n",
      "Train Epoch: 67 [3200/10451 (31%)]\tLoss: 0.365671\n",
      "Train Epoch: 67 [6400/10451 (61%)]\tLoss: 0.411201\n",
      "Train Epoch: 67 [9600/10451 (92%)]\tLoss: 0.641223\n",
      "-> Train Epoch: 67 \tLoss: 0.413944\n",
      "Valid set: Average loss: 0.8523, Accuracy: 1877/2613 (72%)\n",
      "\n",
      "Train Epoch: 68 [0/10451 (0%)]\tLoss: 0.283425\n",
      "Train Epoch: 68 [3200/10451 (31%)]\tLoss: 0.504462\n",
      "Train Epoch: 68 [6400/10451 (61%)]\tLoss: 0.282465\n",
      "Train Epoch: 68 [9600/10451 (92%)]\tLoss: 0.266065\n",
      "-> Train Epoch: 68 \tLoss: 0.417571\n",
      "Valid set: Average loss: 0.8492, Accuracy: 1863/2613 (71%)\n",
      "\n",
      "Train Epoch: 69 [0/10451 (0%)]\tLoss: 0.736409\n",
      "Train Epoch: 69 [3200/10451 (31%)]\tLoss: 0.487110\n",
      "Train Epoch: 69 [6400/10451 (61%)]\tLoss: 0.444114\n",
      "Train Epoch: 69 [9600/10451 (92%)]\tLoss: 0.368306\n",
      "-> Train Epoch: 69 \tLoss: 0.404553\n",
      "Valid set: Average loss: 0.8528, Accuracy: 1894/2613 (72%)\n",
      "\n",
      "Train Epoch: 70 [0/10451 (0%)]\tLoss: 0.542962\n",
      "Train Epoch: 70 [3200/10451 (31%)]\tLoss: 0.242496\n",
      "Train Epoch: 70 [6400/10451 (61%)]\tLoss: 0.466688\n",
      "Train Epoch: 70 [9600/10451 (92%)]\tLoss: 0.476586\n",
      "-> Train Epoch: 70 \tLoss: 0.404422\n",
      "Valid set: Average loss: 0.7906, Accuracy: 1885/2613 (72%)\n",
      "\n",
      "Train Epoch: 71 [0/10451 (0%)]\tLoss: 0.323899\n",
      "Train Epoch: 71 [3200/10451 (31%)]\tLoss: 0.445385\n",
      "Train Epoch: 71 [6400/10451 (61%)]\tLoss: 0.481059\n",
      "Train Epoch: 71 [9600/10451 (92%)]\tLoss: 0.415331\n",
      "-> Train Epoch: 71 \tLoss: 0.398001\n",
      "Valid set: Average loss: 0.8333, Accuracy: 1893/2613 (72%)\n",
      "\n",
      "Train Epoch: 72 [0/10451 (0%)]\tLoss: 0.495380\n",
      "Train Epoch: 72 [3200/10451 (31%)]\tLoss: 0.417148\n",
      "Train Epoch: 72 [6400/10451 (61%)]\tLoss: 0.296347\n",
      "Train Epoch: 72 [9600/10451 (92%)]\tLoss: 0.176697\n",
      "-> Train Epoch: 72 \tLoss: 0.387597\n",
      "Valid set: Average loss: 0.7716, Accuracy: 1922/2613 (74%)\n",
      "\n",
      "Train Epoch: 73 [0/10451 (0%)]\tLoss: 0.197388\n",
      "Train Epoch: 73 [3200/10451 (31%)]\tLoss: 0.375699\n",
      "Train Epoch: 73 [6400/10451 (61%)]\tLoss: 0.240494\n",
      "Train Epoch: 73 [9600/10451 (92%)]\tLoss: 0.328784\n",
      "-> Train Epoch: 73 \tLoss: 0.401981\n",
      "Valid set: Average loss: 0.7930, Accuracy: 1926/2613 (74%)\n",
      "\n",
      "Train Epoch: 74 [0/10451 (0%)]\tLoss: 0.226903\n",
      "Train Epoch: 74 [3200/10451 (31%)]\tLoss: 0.639856\n",
      "Train Epoch: 74 [6400/10451 (61%)]\tLoss: 0.333113\n",
      "Train Epoch: 74 [9600/10451 (92%)]\tLoss: 0.695038\n",
      "-> Train Epoch: 74 \tLoss: 0.398382\n",
      "Valid set: Average loss: 0.7689, Accuracy: 1949/2613 (75%)\n",
      "\n",
      "Train Epoch: 75 [0/10451 (0%)]\tLoss: 0.596839\n",
      "Train Epoch: 75 [3200/10451 (31%)]\tLoss: 0.525859\n",
      "Train Epoch: 75 [6400/10451 (61%)]\tLoss: 0.548986\n",
      "Train Epoch: 75 [9600/10451 (92%)]\tLoss: 0.474195\n",
      "-> Train Epoch: 75 \tLoss: 0.401465\n",
      "Valid set: Average loss: 0.7450, Accuracy: 1924/2613 (74%)\n",
      "\n",
      "Train Epoch: 76 [0/10451 (0%)]\tLoss: 0.595531\n",
      "Train Epoch: 76 [3200/10451 (31%)]\tLoss: 0.470285\n",
      "Train Epoch: 76 [6400/10451 (61%)]\tLoss: 0.642696\n",
      "Train Epoch: 76 [9600/10451 (92%)]\tLoss: 0.393596\n",
      "-> Train Epoch: 76 \tLoss: 0.385778\n",
      "Valid set: Average loss: 0.8029, Accuracy: 1906/2613 (73%)\n",
      "\n",
      "Train Epoch: 77 [0/10451 (0%)]\tLoss: 0.565148\n",
      "Train Epoch: 77 [3200/10451 (31%)]\tLoss: 0.563061\n",
      "Train Epoch: 77 [6400/10451 (61%)]\tLoss: 0.260303\n",
      "Train Epoch: 77 [9600/10451 (92%)]\tLoss: 0.573817\n",
      "-> Train Epoch: 77 \tLoss: 0.392597\n",
      "Valid set: Average loss: 0.8494, Accuracy: 1895/2613 (73%)\n",
      "\n",
      "Train Epoch: 78 [0/10451 (0%)]\tLoss: 0.286645\n",
      "Train Epoch: 78 [3200/10451 (31%)]\tLoss: 0.331244\n",
      "Train Epoch: 78 [6400/10451 (61%)]\tLoss: 0.384572\n",
      "Train Epoch: 78 [9600/10451 (92%)]\tLoss: 0.300860\n",
      "-> Train Epoch: 78 \tLoss: 0.372253\n",
      "Valid set: Average loss: 0.7713, Accuracy: 1938/2613 (74%)\n",
      "\n",
      "Train Epoch: 79 [0/10451 (0%)]\tLoss: 0.128602\n",
      "Train Epoch: 79 [3200/10451 (31%)]\tLoss: 0.426449\n",
      "Train Epoch: 79 [6400/10451 (61%)]\tLoss: 0.282070\n",
      "Train Epoch: 79 [9600/10451 (92%)]\tLoss: 0.426983\n",
      "-> Train Epoch: 79 \tLoss: 0.367988\n",
      "Valid set: Average loss: 0.8276, Accuracy: 1910/2613 (73%)\n",
      "\n",
      "Train Epoch: 80 [0/10451 (0%)]\tLoss: 0.377148\n",
      "Train Epoch: 80 [3200/10451 (31%)]\tLoss: 0.421497\n",
      "Train Epoch: 80 [6400/10451 (61%)]\tLoss: 0.507013\n",
      "Train Epoch: 80 [9600/10451 (92%)]\tLoss: 0.423034\n",
      "-> Train Epoch: 80 \tLoss: 0.377842\n",
      "Valid set: Average loss: 0.8212, Accuracy: 1915/2613 (73%)\n",
      "\n",
      "Train Epoch: 81 [0/10451 (0%)]\tLoss: 0.135471\n",
      "Train Epoch: 81 [3200/10451 (31%)]\tLoss: 0.401619\n",
      "Train Epoch: 81 [6400/10451 (61%)]\tLoss: 0.466461\n",
      "Train Epoch: 81 [9600/10451 (92%)]\tLoss: 0.396377\n",
      "-> Train Epoch: 81 \tLoss: 0.371284\n",
      "Valid set: Average loss: 0.7725, Accuracy: 1957/2613 (75%)\n",
      "\n",
      "Train Epoch: 82 [0/10451 (0%)]\tLoss: 0.359031\n",
      "Train Epoch: 82 [3200/10451 (31%)]\tLoss: 0.209876\n",
      "Train Epoch: 82 [6400/10451 (61%)]\tLoss: 0.565760\n",
      "Train Epoch: 82 [9600/10451 (92%)]\tLoss: 0.262388\n",
      "-> Train Epoch: 82 \tLoss: 0.355321\n",
      "Valid set: Average loss: 0.8499, Accuracy: 1870/2613 (72%)\n",
      "\n",
      "Train Epoch: 83 [0/10451 (0%)]\tLoss: 0.351434\n",
      "Train Epoch: 83 [3200/10451 (31%)]\tLoss: 0.341456\n",
      "Train Epoch: 83 [6400/10451 (61%)]\tLoss: 0.449679\n",
      "Train Epoch: 83 [9600/10451 (92%)]\tLoss: 0.307182\n",
      "-> Train Epoch: 83 \tLoss: 0.363709\n",
      "Valid set: Average loss: 0.8299, Accuracy: 1913/2613 (73%)\n",
      "\n",
      "Train Epoch: 84 [0/10451 (0%)]\tLoss: 0.442274\n",
      "Train Epoch: 84 [3200/10451 (31%)]\tLoss: 0.232459\n",
      "Train Epoch: 84 [6400/10451 (61%)]\tLoss: 0.455411\n",
      "Train Epoch: 84 [9600/10451 (92%)]\tLoss: 0.431019\n",
      "-> Train Epoch: 84 \tLoss: 0.342121\n",
      "Valid set: Average loss: 0.8309, Accuracy: 1909/2613 (73%)\n",
      "\n",
      "Train Epoch: 85 [0/10451 (0%)]\tLoss: 0.530983\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 85 [3200/10451 (31%)]\tLoss: 0.207593\n",
      "Train Epoch: 85 [6400/10451 (61%)]\tLoss: 0.457414\n",
      "Train Epoch: 85 [9600/10451 (92%)]\tLoss: 0.297357\n",
      "-> Train Epoch: 85 \tLoss: 0.363202\n",
      "Valid set: Average loss: 0.8302, Accuracy: 1917/2613 (73%)\n",
      "\n",
      "Train Epoch: 86 [0/10451 (0%)]\tLoss: 0.511828\n",
      "Train Epoch: 86 [3200/10451 (31%)]\tLoss: 0.241247\n",
      "Train Epoch: 86 [6400/10451 (61%)]\tLoss: 0.257316\n",
      "Train Epoch: 86 [9600/10451 (92%)]\tLoss: 0.646910\n",
      "-> Train Epoch: 86 \tLoss: 0.356624\n",
      "Valid set: Average loss: 0.8279, Accuracy: 1908/2613 (73%)\n",
      "\n",
      "Train Epoch: 87 [0/10451 (0%)]\tLoss: 0.306411\n",
      "Train Epoch: 87 [3200/10451 (31%)]\tLoss: 0.221371\n",
      "Train Epoch: 87 [6400/10451 (61%)]\tLoss: 0.305745\n",
      "Train Epoch: 87 [9600/10451 (92%)]\tLoss: 0.622052\n",
      "-> Train Epoch: 87 \tLoss: 0.354489\n",
      "Valid set: Average loss: 0.7558, Accuracy: 1951/2613 (75%)\n",
      "\n",
      "Train Epoch: 88 [0/10451 (0%)]\tLoss: 0.417594\n",
      "Train Epoch: 88 [3200/10451 (31%)]\tLoss: 0.350899\n",
      "Train Epoch: 88 [6400/10451 (61%)]\tLoss: 0.437475\n",
      "Train Epoch: 88 [9600/10451 (92%)]\tLoss: 0.427637\n",
      "-> Train Epoch: 88 \tLoss: 0.358690\n",
      "Valid set: Average loss: 0.7298, Accuracy: 1984/2613 (76%)\n",
      "\n",
      "Train Epoch: 89 [0/10451 (0%)]\tLoss: 0.347407\n",
      "Train Epoch: 89 [3200/10451 (31%)]\tLoss: 0.238125\n",
      "Train Epoch: 89 [6400/10451 (61%)]\tLoss: 0.382486\n",
      "Train Epoch: 89 [9600/10451 (92%)]\tLoss: 0.626189\n",
      "-> Train Epoch: 89 \tLoss: 0.350508\n",
      "Valid set: Average loss: 0.7732, Accuracy: 1921/2613 (74%)\n",
      "\n",
      "Train Epoch: 90 [0/10451 (0%)]\tLoss: 0.264733\n",
      "Train Epoch: 90 [3200/10451 (31%)]\tLoss: 0.761084\n",
      "Train Epoch: 90 [6400/10451 (61%)]\tLoss: 0.682859\n",
      "Train Epoch: 90 [9600/10451 (92%)]\tLoss: 0.279146\n",
      "-> Train Epoch: 90 \tLoss: 0.357150\n",
      "Valid set: Average loss: 0.7622, Accuracy: 1945/2613 (74%)\n",
      "\n",
      "Train Epoch: 91 [0/10451 (0%)]\tLoss: 0.083428\n",
      "Train Epoch: 91 [3200/10451 (31%)]\tLoss: 0.250722\n",
      "Train Epoch: 91 [6400/10451 (61%)]\tLoss: 0.302376\n",
      "Train Epoch: 91 [9600/10451 (92%)]\tLoss: 0.353263\n",
      "-> Train Epoch: 91 \tLoss: 0.358149\n",
      "Valid set: Average loss: 0.7646, Accuracy: 1962/2613 (75%)\n",
      "\n",
      "Train Epoch: 92 [0/10451 (0%)]\tLoss: 0.371321\n",
      "Train Epoch: 92 [3200/10451 (31%)]\tLoss: 0.364328\n",
      "Train Epoch: 92 [6400/10451 (61%)]\tLoss: 0.669681\n",
      "Train Epoch: 92 [9600/10451 (92%)]\tLoss: 0.353302\n",
      "-> Train Epoch: 92 \tLoss: 0.350694\n",
      "Valid set: Average loss: 0.8137, Accuracy: 1914/2613 (73%)\n",
      "\n",
      "Train Epoch: 93 [0/10451 (0%)]\tLoss: 0.184223\n",
      "Train Epoch: 93 [3200/10451 (31%)]\tLoss: 0.254472\n",
      "Train Epoch: 93 [6400/10451 (61%)]\tLoss: 0.293433\n",
      "Train Epoch: 93 [9600/10451 (92%)]\tLoss: 0.330403\n",
      "-> Train Epoch: 93 \tLoss: 0.336931\n",
      "Valid set: Average loss: 0.7845, Accuracy: 1947/2613 (75%)\n",
      "\n",
      "Train Epoch: 94 [0/10451 (0%)]\tLoss: 0.341255\n",
      "Train Epoch: 94 [3200/10451 (31%)]\tLoss: 0.315689\n",
      "Train Epoch: 94 [6400/10451 (61%)]\tLoss: 0.303176\n",
      "Train Epoch: 94 [9600/10451 (92%)]\tLoss: 0.140738\n",
      "-> Train Epoch: 94 \tLoss: 0.345746\n",
      "Valid set: Average loss: 0.8211, Accuracy: 1941/2613 (74%)\n",
      "\n",
      "Train Epoch: 95 [0/10451 (0%)]\tLoss: 0.169865\n",
      "Train Epoch: 95 [3200/10451 (31%)]\tLoss: 0.123688\n",
      "Train Epoch: 95 [6400/10451 (61%)]\tLoss: 0.313283\n",
      "Train Epoch: 95 [9600/10451 (92%)]\tLoss: 0.242766\n",
      "-> Train Epoch: 95 \tLoss: 0.332317\n",
      "Valid set: Average loss: 0.7853, Accuracy: 1967/2613 (75%)\n",
      "\n",
      "Train Epoch: 96 [0/10451 (0%)]\tLoss: 0.245968\n",
      "Train Epoch: 96 [3200/10451 (31%)]\tLoss: 0.114394\n",
      "Train Epoch: 96 [6400/10451 (61%)]\tLoss: 0.359693\n",
      "Train Epoch: 96 [9600/10451 (92%)]\tLoss: 0.687688\n",
      "-> Train Epoch: 96 \tLoss: 0.332800\n",
      "Valid set: Average loss: 0.7299, Accuracy: 1995/2613 (76%)\n",
      "\n",
      "Train Epoch: 97 [0/10451 (0%)]\tLoss: 0.403619\n",
      "Train Epoch: 97 [3200/10451 (31%)]\tLoss: 0.360529\n",
      "Train Epoch: 97 [6400/10451 (61%)]\tLoss: 0.345361\n",
      "Train Epoch: 97 [9600/10451 (92%)]\tLoss: 0.378133\n",
      "-> Train Epoch: 97 \tLoss: 0.338556\n",
      "Valid set: Average loss: 0.6707, Accuracy: 2010/2613 (77%)\n",
      "\n",
      "Train Epoch: 98 [0/10451 (0%)]\tLoss: 0.318235\n",
      "Train Epoch: 98 [3200/10451 (31%)]\tLoss: 0.296504\n",
      "Train Epoch: 98 [6400/10451 (61%)]\tLoss: 0.238012\n",
      "Train Epoch: 98 [9600/10451 (92%)]\tLoss: 0.276346\n",
      "-> Train Epoch: 98 \tLoss: 0.333652\n",
      "Valid set: Average loss: 0.7493, Accuracy: 1975/2613 (76%)\n",
      "\n",
      "Train Epoch: 99 [0/10451 (0%)]\tLoss: 0.345278\n",
      "Train Epoch: 99 [3200/10451 (31%)]\tLoss: 0.269607\n",
      "Train Epoch: 99 [6400/10451 (61%)]\tLoss: 0.311369\n",
      "Train Epoch: 99 [9600/10451 (92%)]\tLoss: 0.404898\n",
      "-> Train Epoch: 99 \tLoss: 0.338233\n",
      "Valid set: Average loss: 0.7590, Accuracy: 1953/2613 (75%)\n",
      "\n",
      "Train Epoch: 100 [0/10451 (0%)]\tLoss: 0.348472\n",
      "Train Epoch: 100 [3200/10451 (31%)]\tLoss: 0.191518\n",
      "Train Epoch: 100 [6400/10451 (61%)]\tLoss: 0.518775\n",
      "Train Epoch: 100 [9600/10451 (92%)]\tLoss: 0.379448\n",
      "-> Train Epoch: 100 \tLoss: 0.346621\n",
      "Valid set: Average loss: 0.7819, Accuracy: 1947/2613 (75%)\n",
      "\n",
      "Train Epoch: 101 [0/10451 (0%)]\tLoss: 0.224288\n",
      "Train Epoch: 101 [3200/10451 (31%)]\tLoss: 0.354460\n",
      "Train Epoch: 101 [6400/10451 (61%)]\tLoss: 0.436286\n",
      "Train Epoch: 101 [9600/10451 (92%)]\tLoss: 0.201106\n",
      "-> Train Epoch: 101 \tLoss: 0.332272\n",
      "Valid set: Average loss: 0.7565, Accuracy: 1962/2613 (75%)\n",
      "\n",
      "Train Epoch: 102 [0/10451 (0%)]\tLoss: 0.137425\n",
      "Train Epoch: 102 [3200/10451 (31%)]\tLoss: 0.683510\n",
      "Train Epoch: 102 [6400/10451 (61%)]\tLoss: 0.437290\n",
      "Train Epoch: 102 [9600/10451 (92%)]\tLoss: 0.203417\n",
      "-> Train Epoch: 102 \tLoss: 0.329290\n",
      "Valid set: Average loss: 0.7720, Accuracy: 1962/2613 (75%)\n",
      "\n",
      "Train Epoch: 103 [0/10451 (0%)]\tLoss: 0.479228\n",
      "Train Epoch: 103 [3200/10451 (31%)]\tLoss: 0.492406\n",
      "Train Epoch: 103 [6400/10451 (61%)]\tLoss: 0.671037\n",
      "Train Epoch: 103 [9600/10451 (92%)]\tLoss: 0.124281\n",
      "-> Train Epoch: 103 \tLoss: 0.334684\n",
      "Valid set: Average loss: 0.6965, Accuracy: 2000/2613 (77%)\n",
      "\n",
      "Train Epoch: 104 [0/10451 (0%)]\tLoss: 0.267663\n",
      "Train Epoch: 104 [3200/10451 (31%)]\tLoss: 0.532083\n",
      "Train Epoch: 104 [6400/10451 (61%)]\tLoss: 0.292619\n",
      "Train Epoch: 104 [9600/10451 (92%)]\tLoss: 0.265150\n",
      "-> Train Epoch: 104 \tLoss: 0.325763\n",
      "Valid set: Average loss: 0.7896, Accuracy: 1943/2613 (74%)\n",
      "\n",
      "Train Epoch: 105 [0/10451 (0%)]\tLoss: 0.447559\n",
      "Train Epoch: 105 [3200/10451 (31%)]\tLoss: 0.290773\n",
      "Train Epoch: 105 [6400/10451 (61%)]\tLoss: 0.161411\n",
      "Train Epoch: 105 [9600/10451 (92%)]\tLoss: 0.205537\n",
      "-> Train Epoch: 105 \tLoss: 0.340266\n",
      "Valid set: Average loss: 0.7523, Accuracy: 1973/2613 (76%)\n",
      "\n",
      "Train Epoch: 106 [0/10451 (0%)]\tLoss: 0.208298\n",
      "Train Epoch: 106 [3200/10451 (31%)]\tLoss: 0.318003\n",
      "Train Epoch: 106 [6400/10451 (61%)]\tLoss: 0.356077\n",
      "Train Epoch: 106 [9600/10451 (92%)]\tLoss: 0.240894\n",
      "-> Train Epoch: 106 \tLoss: 0.324367\n",
      "Valid set: Average loss: 0.7489, Accuracy: 2001/2613 (77%)\n",
      "\n",
      "Train Epoch: 107 [0/10451 (0%)]\tLoss: 0.268219\n",
      "Train Epoch: 107 [3200/10451 (31%)]\tLoss: 0.206474\n",
      "Train Epoch: 107 [6400/10451 (61%)]\tLoss: 0.184525\n",
      "Train Epoch: 107 [9600/10451 (92%)]\tLoss: 0.371160\n",
      "-> Train Epoch: 107 \tLoss: 0.319561\n",
      "Valid set: Average loss: 0.7502, Accuracy: 1962/2613 (75%)\n",
      "\n",
      "Train Epoch: 108 [0/10451 (0%)]\tLoss: 0.210232\n",
      "Train Epoch: 108 [3200/10451 (31%)]\tLoss: 0.228055\n",
      "Train Epoch: 108 [6400/10451 (61%)]\tLoss: 0.330399\n",
      "Train Epoch: 108 [9600/10451 (92%)]\tLoss: 0.537589\n",
      "-> Train Epoch: 108 \tLoss: 0.325870\n",
      "Valid set: Average loss: 0.7921, Accuracy: 1945/2613 (74%)\n",
      "\n",
      "Train Epoch: 109 [0/10451 (0%)]\tLoss: 0.483695\n",
      "Train Epoch: 109 [3200/10451 (31%)]\tLoss: 0.137246\n",
      "Train Epoch: 109 [6400/10451 (61%)]\tLoss: 0.654810\n",
      "Train Epoch: 109 [9600/10451 (92%)]\tLoss: 0.389150\n",
      "-> Train Epoch: 109 \tLoss: 0.312004\n",
      "Valid set: Average loss: 0.8400, Accuracy: 1935/2613 (74%)\n",
      "\n",
      "Train Epoch: 110 [0/10451 (0%)]\tLoss: 0.465179\n",
      "Train Epoch: 110 [3200/10451 (31%)]\tLoss: 0.208793\n",
      "Train Epoch: 110 [6400/10451 (61%)]\tLoss: 0.200309\n",
      "Train Epoch: 110 [9600/10451 (92%)]\tLoss: 0.321835\n",
      "-> Train Epoch: 110 \tLoss: 0.323240\n",
      "Valid set: Average loss: 0.7886, Accuracy: 1938/2613 (74%)\n",
      "\n",
      "Train Epoch: 111 [0/10451 (0%)]\tLoss: 0.498434\n",
      "Train Epoch: 111 [3200/10451 (31%)]\tLoss: 0.345851\n",
      "Train Epoch: 111 [6400/10451 (61%)]\tLoss: 0.292429\n",
      "Train Epoch: 111 [9600/10451 (92%)]\tLoss: 0.208376\n",
      "-> Train Epoch: 111 \tLoss: 0.317479\n",
      "Valid set: Average loss: 0.7112, Accuracy: 2017/2613 (77%)\n",
      "\n",
      "Train Epoch: 112 [0/10451 (0%)]\tLoss: 0.153049\n",
      "Train Epoch: 112 [3200/10451 (31%)]\tLoss: 0.174103\n",
      "Train Epoch: 112 [6400/10451 (61%)]\tLoss: 0.324721\n",
      "Train Epoch: 112 [9600/10451 (92%)]\tLoss: 0.252322\n",
      "-> Train Epoch: 112 \tLoss: 0.298799\n",
      "Valid set: Average loss: 0.7417, Accuracy: 1979/2613 (76%)\n",
      "\n",
      "Train Epoch: 113 [0/10451 (0%)]\tLoss: 0.233761\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 113 [3200/10451 (31%)]\tLoss: 0.324471\n",
      "Train Epoch: 113 [6400/10451 (61%)]\tLoss: 0.111526\n",
      "Train Epoch: 113 [9600/10451 (92%)]\tLoss: 0.074086\n",
      "-> Train Epoch: 113 \tLoss: 0.315506\n",
      "Valid set: Average loss: 0.6982, Accuracy: 2007/2613 (77%)\n",
      "\n",
      "Train Epoch: 114 [0/10451 (0%)]\tLoss: 0.218804\n",
      "Train Epoch: 114 [3200/10451 (31%)]\tLoss: 0.453606\n",
      "Train Epoch: 114 [6400/10451 (61%)]\tLoss: 0.357080\n",
      "Train Epoch: 114 [9600/10451 (92%)]\tLoss: 0.118776\n",
      "-> Train Epoch: 114 \tLoss: 0.302097\n",
      "Valid set: Average loss: 0.7447, Accuracy: 1992/2613 (76%)\n",
      "\n",
      "Train Epoch: 115 [0/10451 (0%)]\tLoss: 0.314632\n",
      "Train Epoch: 115 [3200/10451 (31%)]\tLoss: 0.330005\n",
      "Train Epoch: 115 [6400/10451 (61%)]\tLoss: 0.303933\n",
      "Train Epoch: 115 [9600/10451 (92%)]\tLoss: 0.286043\n",
      "-> Train Epoch: 115 \tLoss: 0.314509\n",
      "Valid set: Average loss: 0.7710, Accuracy: 1980/2613 (76%)\n",
      "\n",
      "Train Epoch: 116 [0/10451 (0%)]\tLoss: 0.315657\n",
      "Train Epoch: 116 [3200/10451 (31%)]\tLoss: 0.170874\n",
      "Train Epoch: 116 [6400/10451 (61%)]\tLoss: 0.235061\n",
      "Train Epoch: 116 [9600/10451 (92%)]\tLoss: 0.365398\n",
      "-> Train Epoch: 116 \tLoss: 0.298227\n",
      "Valid set: Average loss: 0.7370, Accuracy: 2014/2613 (77%)\n",
      "\n",
      "Train Epoch: 117 [0/10451 (0%)]\tLoss: 0.408720\n",
      "Train Epoch: 117 [3200/10451 (31%)]\tLoss: 0.273082\n",
      "Train Epoch: 117 [6400/10451 (61%)]\tLoss: 0.271105\n",
      "Train Epoch: 117 [9600/10451 (92%)]\tLoss: 0.230075\n",
      "-> Train Epoch: 117 \tLoss: 0.297499\n",
      "Valid set: Average loss: 0.7231, Accuracy: 2004/2613 (77%)\n",
      "\n",
      "Train Epoch: 118 [0/10451 (0%)]\tLoss: 0.177434\n",
      "Train Epoch: 118 [3200/10451 (31%)]\tLoss: 0.240120\n",
      "Train Epoch: 118 [6400/10451 (61%)]\tLoss: 0.238352\n",
      "Train Epoch: 118 [9600/10451 (92%)]\tLoss: 0.416249\n",
      "-> Train Epoch: 118 \tLoss: 0.312903\n",
      "Valid set: Average loss: 0.7273, Accuracy: 1996/2613 (76%)\n",
      "\n",
      "Train Epoch: 119 [0/10451 (0%)]\tLoss: 0.112880\n",
      "Train Epoch: 119 [3200/10451 (31%)]\tLoss: 0.342167\n",
      "Train Epoch: 119 [6400/10451 (61%)]\tLoss: 0.252073\n",
      "Train Epoch: 119 [9600/10451 (92%)]\tLoss: 0.230431\n",
      "-> Train Epoch: 119 \tLoss: 0.315781\n",
      "Valid set: Average loss: 0.7215, Accuracy: 1994/2613 (76%)\n",
      "\n",
      "Train Epoch: 120 [0/10451 (0%)]\tLoss: 0.066807\n",
      "Train Epoch: 120 [3200/10451 (31%)]\tLoss: 0.083255\n",
      "Train Epoch: 120 [6400/10451 (61%)]\tLoss: 0.417010\n",
      "Train Epoch: 120 [9600/10451 (92%)]\tLoss: 0.205073\n",
      "-> Train Epoch: 120 \tLoss: 0.313757\n",
      "Valid set: Average loss: 0.6668, Accuracy: 2040/2613 (78%)\n",
      "\n",
      "Train Epoch: 121 [0/10451 (0%)]\tLoss: 0.188883\n",
      "Train Epoch: 121 [3200/10451 (31%)]\tLoss: 0.145610\n",
      "Train Epoch: 121 [6400/10451 (61%)]\tLoss: 0.441782\n",
      "Train Epoch: 121 [9600/10451 (92%)]\tLoss: 0.190111\n",
      "-> Train Epoch: 121 \tLoss: 0.303084\n",
      "Valid set: Average loss: 0.7068, Accuracy: 2016/2613 (77%)\n",
      "\n",
      "Train Epoch: 122 [0/10451 (0%)]\tLoss: 0.263724\n",
      "Train Epoch: 122 [3200/10451 (31%)]\tLoss: 0.338675\n",
      "Train Epoch: 122 [6400/10451 (61%)]\tLoss: 0.267620\n",
      "Train Epoch: 122 [9600/10451 (92%)]\tLoss: 0.246691\n",
      "-> Train Epoch: 122 \tLoss: 0.299699\n",
      "Valid set: Average loss: 0.7046, Accuracy: 2027/2613 (78%)\n",
      "\n",
      "Train Epoch: 123 [0/10451 (0%)]\tLoss: 0.207206\n",
      "Train Epoch: 123 [3200/10451 (31%)]\tLoss: 0.123009\n",
      "Train Epoch: 123 [6400/10451 (61%)]\tLoss: 0.411334\n",
      "Train Epoch: 123 [9600/10451 (92%)]\tLoss: 0.474173\n",
      "-> Train Epoch: 123 \tLoss: 0.299388\n",
      "Valid set: Average loss: 0.7293, Accuracy: 2013/2613 (77%)\n",
      "\n",
      "Train Epoch: 124 [0/10451 (0%)]\tLoss: 0.311122\n",
      "Train Epoch: 124 [3200/10451 (31%)]\tLoss: 0.292661\n",
      "Train Epoch: 124 [6400/10451 (61%)]\tLoss: 0.415943\n",
      "Train Epoch: 124 [9600/10451 (92%)]\tLoss: 0.234447\n",
      "-> Train Epoch: 124 \tLoss: 0.293681\n",
      "Valid set: Average loss: 0.7017, Accuracy: 2018/2613 (77%)\n",
      "\n",
      "Train Epoch: 125 [0/10451 (0%)]\tLoss: 0.481010\n",
      "Train Epoch: 125 [3200/10451 (31%)]\tLoss: 0.426720\n",
      "Train Epoch: 125 [6400/10451 (61%)]\tLoss: 0.498665\n",
      "Train Epoch: 125 [9600/10451 (92%)]\tLoss: 0.269063\n",
      "-> Train Epoch: 125 \tLoss: 0.298804\n",
      "Valid set: Average loss: 0.6769, Accuracy: 2041/2613 (78%)\n",
      "\n",
      "Train Epoch: 126 [0/10451 (0%)]\tLoss: 0.247750\n",
      "Train Epoch: 126 [3200/10451 (31%)]\tLoss: 0.151985\n",
      "Train Epoch: 126 [6400/10451 (61%)]\tLoss: 0.407510\n",
      "Train Epoch: 126 [9600/10451 (92%)]\tLoss: 0.169905\n",
      "-> Train Epoch: 126 \tLoss: 0.305598\n",
      "Valid set: Average loss: 0.7101, Accuracy: 1985/2613 (76%)\n",
      "\n",
      "Train Epoch: 127 [0/10451 (0%)]\tLoss: 0.579091\n",
      "Train Epoch: 127 [3200/10451 (31%)]\tLoss: 0.134583\n",
      "Train Epoch: 127 [6400/10451 (61%)]\tLoss: 0.326796\n",
      "Train Epoch: 127 [9600/10451 (92%)]\tLoss: 0.310712\n",
      "-> Train Epoch: 127 \tLoss: 0.299254\n",
      "Valid set: Average loss: 0.7156, Accuracy: 2018/2613 (77%)\n",
      "\n",
      "Train Epoch: 128 [0/10451 (0%)]\tLoss: 0.336066\n",
      "Train Epoch: 128 [3200/10451 (31%)]\tLoss: 0.284951\n",
      "Train Epoch: 128 [6400/10451 (61%)]\tLoss: 0.589939\n",
      "Train Epoch: 128 [9600/10451 (92%)]\tLoss: 0.429098\n",
      "-> Train Epoch: 128 \tLoss: 0.289915\n",
      "Valid set: Average loss: 0.7317, Accuracy: 1991/2613 (76%)\n",
      "\n",
      "Train Epoch: 129 [0/10451 (0%)]\tLoss: 0.340103\n",
      "Train Epoch: 129 [3200/10451 (31%)]\tLoss: 0.383424\n",
      "Train Epoch: 129 [6400/10451 (61%)]\tLoss: 0.075350\n",
      "Train Epoch: 129 [9600/10451 (92%)]\tLoss: 0.555127\n",
      "-> Train Epoch: 129 \tLoss: 0.296820\n",
      "Valid set: Average loss: 0.6779, Accuracy: 2038/2613 (78%)\n",
      "\n",
      "Train Epoch: 130 [0/10451 (0%)]\tLoss: 0.268367\n",
      "Train Epoch: 130 [3200/10451 (31%)]\tLoss: 0.267142\n",
      "Train Epoch: 130 [6400/10451 (61%)]\tLoss: 0.342429\n",
      "Train Epoch: 130 [9600/10451 (92%)]\tLoss: 0.232908\n",
      "-> Train Epoch: 130 \tLoss: 0.300786\n",
      "Valid set: Average loss: 0.7089, Accuracy: 2024/2613 (77%)\n",
      "\n",
      "Train Epoch: 131 [0/10451 (0%)]\tLoss: 0.296954\n",
      "Train Epoch: 131 [3200/10451 (31%)]\tLoss: 0.233468\n",
      "Train Epoch: 131 [6400/10451 (61%)]\tLoss: 0.260002\n",
      "Train Epoch: 131 [9600/10451 (92%)]\tLoss: 0.387411\n",
      "-> Train Epoch: 131 \tLoss: 0.289498\n",
      "Valid set: Average loss: 0.6670, Accuracy: 2041/2613 (78%)\n",
      "\n",
      "Train Epoch: 132 [0/10451 (0%)]\tLoss: 0.500193\n",
      "Train Epoch: 132 [3200/10451 (31%)]\tLoss: 0.096789\n",
      "Train Epoch: 132 [6400/10451 (61%)]\tLoss: 0.369250\n",
      "Train Epoch: 132 [9600/10451 (92%)]\tLoss: 0.616053\n",
      "-> Train Epoch: 132 \tLoss: 0.282911\n",
      "Valid set: Average loss: 0.7349, Accuracy: 2014/2613 (77%)\n",
      "\n",
      "Train Epoch: 133 [0/10451 (0%)]\tLoss: 0.577149\n",
      "Train Epoch: 133 [3200/10451 (31%)]\tLoss: 0.272587\n",
      "Train Epoch: 133 [6400/10451 (61%)]\tLoss: 0.423634\n",
      "Train Epoch: 133 [9600/10451 (92%)]\tLoss: 0.345930\n",
      "-> Train Epoch: 133 \tLoss: 0.281896\n",
      "Valid set: Average loss: 0.6917, Accuracy: 2039/2613 (78%)\n",
      "\n",
      "Train Epoch: 134 [0/10451 (0%)]\tLoss: 0.312647\n",
      "Train Epoch: 134 [3200/10451 (31%)]\tLoss: 0.419716\n"
     ]
    }
   ],
   "source": [
    "####################  implement your optimizer ###################################\n",
    "## yo can use any training methods if you want (ex:lr decay, weight decay.....)\n",
    "\n",
    "lr=0.001\n",
    "#optimizer = optim.Adam(model.parameters(), lr, betas=(0.9, 0.999), eps=1e-08, weight_decay=1e-5, amsgrad=False)\n",
    "optimizer = optim.Adam(model.parameters(), lr, betas=(0.9, 0.999), eps=1e-08, weight_decay=1e-5, amsgrad=False)\n",
    "scheduler = ReduceLROnPlateau(optimizer, 'min',factor=0.1, patience=10, min_lr=0.000001, eps=1e-08, threshold=0.0001, threshold_mode='rel', cooldown=0, verbose=True)\n",
    "# start training\n",
    "epochs = 600\n",
    "acc = 0.95\n",
    "for epoch in range(epochs):\n",
    "    #model.train()\n",
    "    loss = train(model, train_data_loader, optimizer, epoch,scheduler)\n",
    "    print('-> Train Epoch: {} \\tLoss: {:.6f}'.format(epoch,loss))\n",
    "    accuracy = valid(model, val_data_loader)\n",
    "    scheduler.step(loss)\n",
    "    if accuracy > acc:\n",
    "        acc = accuracy\n",
    "        print(\"-------------saving model--------------\")\n",
    "        # save the model\n",
    "        torch.save(model, \"model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# load the model so that you don't need to train the model again\n",
    "test_model = torch.load(\"model.pth\").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "image_list = []\n",
    "for filename in glob.glob('testdata/*.png'):\n",
    "    image_list.append(filename)\n",
    "image_list.sort()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "import imageio\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "class TestDataset(Dataset):\n",
    "    def __init__(self, image_list, transform=None):\n",
    "        self.image_list = image_list\n",
    "        #self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "\n",
    "        #img_name = os.path.join(self.root_dir,\n",
    "                                #self.landmarks_frame.iloc[idx, 0])\n",
    "        #image = imageio.imread(self.image_list[idx])\n",
    "        im = Image.open(self.image_list[idx])\n",
    "        #sample = {'image': image}\n",
    "        if self.transform:\n",
    "            im = self.transform(im)\n",
    "\n",
    "        return im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset=TestDataset(image_list,transform1)\n",
    "test_data_loader = torch.utils.data.DataLoader(test_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model,data_loader,image_list):\n",
    "    with torch.no_grad():\n",
    "        num=0\n",
    "        model.eval()\n",
    "        valid_loss = 0\n",
    "        correct = 0\n",
    "        bs = test_data_loader.batch_size\n",
    "        result = []\n",
    "        for i, data in enumerate(test_data_loader):\n",
    "            data = data.to(device)\n",
    "            output = model(data)\n",
    "            pred = output.data.max(1, keepdim=True)[1]                                             # get the index of the max log-probability\n",
    "            arr = pred.data.cpu().numpy()\n",
    "            for j in range(pred.size()[0]):\n",
    "                #file_name = test_data.samples[i*bs+j][0].split('/')[-1]\n",
    "                file_name = image_list[num].split('/')[-1]\n",
    "                result.append((file_name,pred[j].cpu().numpy()[0]))\n",
    "                num+=1\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = test(model,test_data_loader,image_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############## Build the model here ##########\n",
    "'''\n",
    "class ConvNet(nn.Module):\n",
    "    def __init__(self,num_classes=4):\n",
    "    \n",
    "        super(ConvNet, self).__init__()\n",
    "    \n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        return out\n",
    "'''\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Write results to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "with open(\"prediction_0428.csv\", \"w\", newline=\"\") as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow(['Id','Category'])\n",
    "    #for row in result:\n",
    "    #    writer.writerows(row)\n",
    "    writer.writerows(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "'''\n",
    "import glob\n",
    "train_labels=[]\n",
    "#TRAIN_DATA_PATH = 'traindata/'\n",
    "#TEST_BATA_PATH='testdata/'\n",
    "\n",
    "#Airplanes\n",
    "train_images = glob.glob ('traindata/airplane/*.png')\n",
    "airplane_num=len(train_images)\n",
    "for i in range(airplane_num):\n",
    "    train_labels.extend([0])\n",
    "#Bird\n",
    "train_images += glob.glob ('traindata/bird/*.png')\n",
    "bird_num=len(train_images)-airplane_num\n",
    "for i in range(bird_num):\n",
    "    train_labels.extend([1])\n",
    "    \n",
    "#Car\n",
    "train_images += glob.glob ('traindata/car/*.png')\n",
    "car_num=len(train_images) - airplane_num - bird_num\n",
    "for i in range(car_num):\n",
    "    train_labels.extend([2])\n",
    "\n",
    "#Cat\n",
    "train_images += glob.glob ('traindata/cat/*.png')\n",
    "cat_num=len(train_images) - airplane_num - bird_num - car_num\n",
    "for i in range(cat_num):\n",
    "    train_labels.extend([3])\n",
    "\n",
    "#Dog\n",
    "train_images += glob.glob ('traindata/dog/*.png')\n",
    "dog_num=len(train_images) - airplane_num - bird_num - car_num - cat_num\n",
    "for i in range(dog_num):\n",
    "    train_labels.extend([4])\n",
    "    \n",
    "#Dog\n",
    "train_images += glob.glob ('traindata/horse/*.png')\n",
    "horse_num=len(train_images) - airplane_num - bird_num - car_num - cat_num - dog_num\n",
    "for i in range(horse_num):\n",
    "    train_labels.extend([5])\n",
    "    \n",
    "    \n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nclass ImageDataset(Dataset):\\n\\n    def __init__(self, data_root):\\n        self.samples = []\\n        num=0\\n        for objects in os.listdir(data_root): #animals=airplane, bird, car...\\n            objects_folder = os.path.join(data_root, objects)\\n\\n            for categ in os.listdir(objects_folder):\\n                categ_filepath = os.path.join(animals_folder, categ)\\n                self.samples.append()\\n        self.transform = transforms.Compose([transforms.Resize(255),\\n                                             transforms.CenterCrop(224),\\n                                             transforms.ToTensor()])\\n\\n    def __len__(self):\\n        return len(self.samples)\\n\\n    def __getitem__(self, idx):\\n        return self.samples[idx]\\n'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "'''\n",
    "class ImageDataset(Dataset):\n",
    "\n",
    "    def __init__(self, data_root):\n",
    "        self.samples = []\n",
    "        num=0\n",
    "        for objects in os.listdir(data_root): #animals=airplane, bird, car...\n",
    "            objects_folder = os.path.join(data_root, objects)\n",
    "\n",
    "            for categ in os.listdir(objects_folder):\n",
    "                categ_filepath = os.path.join(animals_folder, categ)\n",
    "                self.samples.append()\n",
    "        self.transform = transforms.Compose([transforms.Resize(255),\n",
    "                                             transforms.CenterCrop(224),\n",
    "                                             transforms.ToTensor()])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.samples[idx]\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
